@article{shi2025taskcraft,
  title={TaskCraft: Automated Generation of Agentic Tasks},
  author={Shi, Dingfeng and Cao, Jingyi and Chen, Qianben and Sun, Weichen and Li, Weizhen and Lu, Hongxuan and Dong, Fangchen and Qin, Tianrui and Zhu, King and Yang, Minghao and others},
  journal={arXiv preprint arXiv:2506.10055},
  year={2025}
}

@misc{schulman2017proximalpolicyoptimizationalgorithms,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1707.06347}, 
}

@misc{shao2024deepseekmathpushinglimitsmathematical,
      title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}, 
      author={Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Xiao Bi and Haowei Zhang and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
      year={2024},
      eprint={2402.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.03300}, 
}

@inproceedings{hong2023metagpt,
  title={{MetaGPT}: Meta Programming for A Multi-Agent Collaborative Framework},
  author={Hong, Sirui and Zhuge, Mingchen and Chen, Jonathan and Zheng, Xiawu and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=VtmBAGCN7o}
}

@inproceedings{shen2023hugginggpt,
  title={{HuggingGPT}: Solving {AI} Tasks with {ChatGPT} and its Friends in {Hugging Face}},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yu},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  pages={7136--7153},
  year={2023},
  url={https://proceedings.neurips.cc/paper_files/paper/2023/hash/694229972352433017a117500583a547-Abstract-Conference.html}
}

@inproceedings{jimenez2024swebench,
      title={{SWE-bench}: Can Language Models Resolve Real-world Github Issues?},
      author={Carlos E. Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik R. Narasimhan},
      booktitle={The Twelfth International Conference on Learning Representations},
      year={2024},
      url={https://openreview.net/forum?id=VTF8yNQM66}
}

@misc{xu2025kodcode,
      title={{KodCode}: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding}, 
      author={Zhangchen Xu and Yang Liu and Yueqin Yin and Mingyuan Zhou and Radha Poovendran},
      year={2025},
      eprint={2503.02951},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{shao2025case2code,
      title={{Case2Code}: Scalable Synthetic Data for Code Generation},
      author={Zheng-Xin Shao and Yeyun Gong and Yelong Shen and Jian Jiao and Ruoss Jia and Yujiu Yang and Nan Duan and Weizhu Chen},
      booktitle={Proceedings of the 31st International Conference on Computational Linguistics},
      year={2025},
      publisher={Association for Computational Linguistics}
}

@inproceedings{xu2025agenttrek,
      title={{AgentTrek}: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials},
      author={Yiheng Xu and Dunjie Lu and Zhennan Shen and Junli Wang and Zekun Wang and Yuchen Mao and Caiming Xiong and Tao Yu},
      booktitle={International Conference on Learning Representations},
      year={2025}
}

@inproceedings{sun-etal-2025-os,
    title = "{OS}-Genesis: Automating {GUI} Agent Trajectory Construction via Reverse Task Synthesis",
    author = "Sun, Qiushi  and
      Cheng, Kanzhi  and
      Ding, Zichen  and
      Jin, Chuanyang  and
      Wang, Yian  and
      Xu, Fangzhi  and
      Wu, Zhenyu  and
      Jia, Chengyou  and
      Chen, Liheng  and
      Liu, Zhoumianze  and
      Kao, Ben  and
      Li, Guohao  and
      He, Junxian  and
      Qiao, Yu  and
      Wu, Zhiyong",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.277/",
    doi = "10.18653/v1/2025.acl-long.277",
    pages = "5555--5579",
    ISBN = "979-8-89176-251-0",
    abstract = "Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, the development of such agents faces a critical bottleneck: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Further, these approaches exhibit significant gaps between the generated data and online environments, alongside limited data diversity. To address this issue, we introduce OS-Genesis, a novel GUI data synthesis pipeline that overcomes the challenges above. Unlike prior methods that rely on preset tasks, OS-Genesis reverse engineers the GUI trajectory construction process. Agents first perceive environments and perform step-level interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesis{'}s cost-effectiveness and its superior data quality and diversity compared to existing synthesis methods."
}

@misc{pahuja2025explorer,
      title={{Explorer}: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents}, 
      author={Vardaan Pahuja and Michael Chang and Hong-Lak Lee and Igor Mordatch and Sergey Levine},
      year={2025},
      eprint={2502.11357},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{qiao2025webresearcher,
      title={{WebResearcher}: Unleashing unbounded reasoning capability in Long-Horizon Agents}, 
      author={Zile Qiao and Shen Huang and Jialong Wu and Kuan Li and Wenbiao Yin and Xinyu Wang and Liwen Zhang and Baixuan Li and Zhengwei Tao and Weizhou Shen and Xixi Wu and Yong Jiang and Pengjun Xie and Fei Huang and Jun Zhang and Jingren Zhou},
      year={2025},
      eprint={2509.13309},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tao2025webshaper,
      title={{WebShaper}: Agentically Data Synthesizing via Information-Seeking Formalization}, 
      author={Zhengwei Tao and Jialong Wu and Wenbiao Yin and Junkai Zhang and Baixuan Li and Haiyang Shen and Kuan Li and Liwen Zhang and Xinyu Wang and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2507.15061},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{shinn2023reflexion,
  title={{Reflexion}: Language Agents with Verbal Reinforcement Learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2303.11366},
  year={2023},
  url={https://arxiv.org/abs/2303.11366}
}

@misc{xu2025amemagenticmemoryllm,
      title={A-MEM: Agentic Memory for LLM Agents}, 
      author={Wujiang Xu and Kai Mei and Hang Gao and Juntao Tan and Zujie Liang and Yongfeng Zhang},
      year={2025},
      eprint={2502.12110},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.12110}, 
}

@misc{li2025websailorv2bridgingchasmproprietary,
      title={WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning}, 
      author={Kuan Li and Zhongwang Zhang and Huifeng Yin and Rui Ye and Yida Zhao and Liwen Zhang and Litu Ou and Dingchu Zhang and Xixi Wu and Jialong Wu and Xinyu Wang and Zile Qiao and Zhen Zhang and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2509.13305},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2509.13305}, 
}

@misc{li2025websailornavigatingsuperhumanreasoning,
      title={WebSailor: Navigating Super-human Reasoning for Web Agent}, 
      author={Kuan Li and Zhongwang Zhang and Huifeng Yin and Liwen Zhang and Litu Ou and Jialong Wu and Wenbiao Yin and Baixuan Li and Zhengwei Tao and Xinyu Wang and Weizhou Shen and Junkai Zhang and Dingchu Zhang and Xixi Wu and Yong Jiang and Ming Yan and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2507.02592},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.02592}, 
}

@misc{wu2025webdancerautonomousinformationseeking,
      title={WebDancer: Towards Autonomous Information Seeking Agency}, 
      author={Jialong Wu and Baixuan Li and Runnan Fang and Wenbiao Yin and Liwen Zhang and Zhengwei Tao and Dingchu Zhang and Zekun Xi and Gang Fu and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2505.22648},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.22648}, 
}


@article{zeng2023agenttuning,
  title={{AgentTuning}: Enabling Generalized Agent Abilities for {LLMs}},
  author={Zeng, Aohan and Liu, Mingdao and Lu, Rui and Wang, Bowen and Liu, Xiao and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2310.12823},
  year={2023},
  url={https://arxiv.org/abs/2310.12823}
}

@article{wilson1999models,
  title={Models in information behaviour research},
  author={Wilson, Tom D},
  journal={Journal of documentation},
  volume={55},
  number={3},
  pages={249--270},
  year={1999},
  publisher={MCB UP Ltd}
}

@misc{openaidr,
    title = {Deep Research System Card} ,
    author = {OpenAI},
    url = {https://cdn.openai.com/deep-research-system-card.pdf},
    year = {2025}
}

@misc{geminidr,
    title = {Gemini Deep Research} ,
    author = {Gemini},
    url = {https://gemini.google.com/app},
    year = {2025}
}

@misc{doubaodr,
    title = {Doubao Deep Research} ,
    author = {Doubao},
    url = {https://www.doubao.com/chat/},
    year = {2025}
}

@misc{kimidr,
    title = {Kimi Deep Research} ,
    author = {Kimi},
    url = {https://www.kimi.com/},
    year = {2025}
}

@misc{grokdr,
    title = {Grok 3 Beta — The Age of Reasoning Agents},
    author = {x.ai},
    url = {https://x.ai/news/grok-3},
    year = {2025}
}

@misc{perplexity,
    title = {Perplexity Deep Research},
    author = {Perplexity},
    url = {https://www.perplexity.ai/},
    year = {2025}
}

@misc{shen2025ragsynthsyntheticdatarobust,
      title={RAGSynth: Synthetic Data for Robust and Faithful RAG Component Optimization}, 
      author={Haiyang Shen and Hang Yan and Zhongshi Xing and Mugeng Liu and Yue Li and Zhiyang Chen and Yuxiang Wang and Jiuzheng Wang and Yun Ma},
      year={2025},
      eprint={2505.10989},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.10989}, 
}

@inproceedings{
shen2025shortcutsbench,
title={ShortcutsBench: A Large-Scale Real-world Benchmark for {API}-based Agents},
author={Haiyang SHEN and Yue Li and Desong Meng and Dongqi Cai and Sheng Qi and Li Zhang and Mengwei Xu and Yun Ma},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=kKILfPkhSz}
}


@misc{jina,
    title = {Jina} ,
    author = {Jina.ai},
    url = {https://jina.ai/},
    year = {2025}
}

@misc{claude,
    title = {Meet Claude} ,
    author = {anthropic},
    url = {https://www.anthropic.com/claude},
    year = {2025}
}

@misc{compge,
    title = {Measuring Compositional Generalization},
    author = {Google},
    url = {https://research.google/blog/measuring-compositional-generalization/},
    year = {2020}
}

@misc{gpt-4.5,
    title = {GPT-4.5 system card} ,
    author = {OpenAI},
    url = {https://openai.com/index/gpt-4-5-system-card/},
    year = {2025}
}

@misc{simpleqa,
    title = {Introducing SimpleQA},
    author = {OpenAI},
    url = {https://openai.com/index/introducing-simpleqa/},
    year = {2025}
}



@misc{qwq,
    title = {QwQ-32B: Embracing the Power of Reinforcement Learning},
    author = {QwQ Team},
    url = {https://qwenlm.github.io/blog/qwq-32b/},
    year = {2025}
}

@article{bc_en,
  title={Browsecomp: A simple yet challenging benchmark for browsing agents},
  author={Wei, Jason and Sun, Zhiqing and Papay, Spencer and McKinney, Scott and Han, Jeffrey and Fulford, Isa and Chung, Hyung Won and Passos, Alex Tachard and Fedus, William and Glaese, Amelia},
  journal={arXiv preprint arXiv:2504.12516},
  year={2025}
}

@article{bc_zh,
  title={Browsecomp-zh: Benchmarking web browsing ability of large language models in chinese},
  author={Zhou, Peilin and Leon, Bruce and Ying, Xiang and Zhang, Can and Shao, Yifan and Ye, Qichen and Chong, Dading and Jin, Zhiling and Xie, Chenxuan and Cao, Meng and others},
  journal={arXiv preprint arXiv:2504.19314},
  year={2025}
}


@article{tao2025prophet,
  title={PROPHET: An Inferable Future Forecasting Benchmark with Causal Intervened Likelihood Estimation},
  author={Tao, Zhengwei and Jin, Zhi and Li, Bincheng and Bai, Xiaoying and Zhao, Haiyan and Dou, Chengfeng and Chen, Xiancai and Li, Jia and Li, Linyu and Tao, Chongyang},
  journal={arXiv preprint arXiv:2504.01509},
  year={2025}
}


@article{li2025search,
  title={Search-o1: Agentic search-enhanced large reasoning models},
  author={Li, Xiaoxi and Dong, Guanting and Jin, Jiajie and Zhang, Yuyao and Zhou, Yujia and Zhu, Yutao and Zhang, Peitian and Dou, Zhicheng},
  journal={arXiv preprint arXiv:2501.05366},
  year={2025}
}

@article{Li2025webthinker,
  author       = {Xiaoxi Li and
                  Jiajie Jin and
                  Guanting Dong and
                  Hongjin Qian and
                  Yutao Zhu and
                  Yongkang Wu and
                  Ji{-}Rong Wen and
                  Zhicheng Dou},
  title        = {WebThinker: Empowering Large Reasoning Models with Deep Research Capability},
  journal      = {CoRR},
  volume       = {abs/2504.21776},
  year         = {2025},
  url          = {https://doi.org/10.48550/arXiv.2504.21776},
  doi          = {10.48550/ARXIV.2504.21776},
  eprinttype    = {arXiv},
  eprint       = {2504.21776},
  timestamp    = {Sun, 25 May 2025 20:50:43 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2504-21776.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{song2025r1,
  title={R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning},
  author={Song, Huatong and Jiang, Jinhao and Min, Yingqian and Chen, Jie and Chen, Zhipeng and Zhao, Wayne Xin and Fang, Lei and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2503.05592},
  year={2025}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}



@article{xin2024deepseek,
  title={Deepseek-prover: Advancing theorem proving in llms through large-scale synthetic data},
  author={Xin, Huajian and Guo, Daya and Shao, Zhihong and Ren, Zhizhou and Zhu, Qihao and Liu, Bo and Ruan, Chong and Li, Wenda and Liang, Xiaodan},
  journal={arXiv preprint arXiv:2405.14333},
  year={2024}
}

@article{ren2025deepseek,
  title={Deepseek-prover-v2: Advancing formal mathematical reasoning via reinforcement learning for subgoal decomposition},
  author={Ren, ZZ and Shao, Zhihong and Song, Junxiao and Xin, Huajian and Wang, Haocheng and Zhao, Wanjia and Zhang, Liyue and Fu, Zhe and Zhu, Qihao and Yang, Dejian and others},
  journal={arXiv preprint arXiv:2504.21801},
  year={2025}
}


@article{lin2025goedel,
  title={Goedel-prover: A frontier model for open-source automated theorem proving},
  author={Lin, Yong and Tang, Shange and Lyu, Bohan and Wu, Jiayun and Lin, Hongzhou and Yang, Kaiyu and Li, Jia and Xia, Mengzhou and Chen, Danqi and Arora, Sanjeev and others},
  journal={arXiv preprint arXiv:2502.07640},
  year={2025}
}

@article{choudhary2023complex,
  title={Complex logical reasoning over knowledge graphs using large language models},
  author={Choudhary, Nurendra and Reddy, Chandan K},
  journal={arXiv preprint arXiv:2305.01157},
  year={2023}
}


@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={53728--53741},
  year={2023}
}

@article{leang2025theorem,
  title={Theorem prover as a judge for synthetic data generation},
  author={Leang, Joshua Ong Jun and Hong, Giwon and Li, Wenda and Cohen, Shay B},
  journal={arXiv preprint arXiv:2502.13137},
  year={2025}
}

@inproceedings{xia2025improving,
  title={Improving complex reasoning over knowledge graph with logic-aware curriculum tuning},
  author={Xia, Tianle and Ding, Liang and Wan, Guojia and Zhan, Yibing and Du, Bo and Tao, Dacheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={12},
  pages={12881--12889},
  year={2025}
}

@misc{o1,
    title={Learning to Reason with {LLMs}},
    author={{OpenAI}},
    url={https://openai.com/index/learning-to-reason-with-llms/},
    year={2024}
}


@article{r1,
  title={{DeepSeek-R1}: Incentivizing reasoning capability in {LLMs} via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{chen2025sft,
  title={Sft or rl? an early investigation into training r1-like reasoning large vision-language models},
  author={Chen, Hardy and Tu, Haoqin and Wang, Fali and Liu, Hui and Tang, Xianfeng and Du, Xinya and Zhou, Yuyin and Xie, Cihang},
  journal={arXiv preprint arXiv:2504.11468},
  year={2025}
}

@article{hu2025open,
  title={Open-reasoner-zero: An open source approach to scaling up reinforcement learning on the base model},
  author={Hu, Jingcheng and Zhang, Yinmin and Han, Qi and Jiang, Daxin and Zhang, Xiangyu and Shum, Heung-Yeung},
  journal={arXiv preprint arXiv:2503.24290},
  year={2025}
}

@article{yu2025dapo,
  title={Dapo: An open-source llm reinforcement learning system at scale},
  author={Yu, Qiying and Zhang, Zheng and Zhu, Ruofei and Yuan, Yufeng and Zuo, Xiaochen and Yue, Yu and Fan, Tiantian and Liu, Gaohong and Liu, Lingjun and Liu, Xin and others},
  journal={arXiv preprint arXiv:2503.14476},
  year={2025}
}

@misc{o3,
  title = {Introducing OpenAI o3 and o4-mini},
  author = {OpenAI},
  url = {https://openai.com/index/introducing-o3-and-o4-mini/},
  year={2025}
}


@misc{grok3,
  title = {Grok 3 Beta — The Age of Reasoning Agents},
  author = {xAI},
  url = {https://x.ai/news/grok-3},
  year={2025}
}

@misc{gpt4.1,
  title = {Introducing OpenAI GPT-4.1},
  author = {OpenAI},
  url = {https://openai.com/index/gpt-4-1/},
  year={2025}
}



@misc{gemini2.5,
  title = {Gemini 2.5},
  author = {Google DeepMind},
  url = {https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/},
  year={2025}
}

@misc{doubao,
  title = {Doubao},
  author = {ByteDance Doubao},
  url = {http://www.doubao.com/},
  year={2025}
}

@inproceedings{mialon2023gaia,
  title={Gaia: a benchmark for general ai assistants},
  author={Mialon, Gr{\'e}goire and Fourrier, Cl{\'e}mentine and Wolf, Thomas and LeCun, Yann and Scialom, Thomas},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{yao2023react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}


@misc{ho2020constructingmultihopqadataset,
      title={Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps}, 
      author={Xanh Ho and Anh-Khoa Duong Nguyen and Saku Sugawara and Akiko Aizawa},
      year={2020},
      eprint={2011.01060},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2011.01060}, 
}

@misc{qwq32b,
    title = {{QwQ-32B}: Embracing the Power of Reinforcement Learning},
    url = {https://qwenlm.github.io/blog/qwq-32b/},
    author = {{Qwen~Team}},
    month = {March},
    year = {2025}
}

@misc{claude3.7,
  title = {Claude 3.7 {Sonnet}},
  author = {Anthropic},
  url = {https://www.anthropic.com/news/claude-3-7-sonnet},
  year={2025}
}

@article{yuan2023scaling,
  title={Scaling relationship on learning mathematical reasoning with large language models},
  author={Yuan, Zheng and Yuan, Hongyi and Li, Chengpeng and Dong, Guanting and Lu, Keming and Tan, Chuanqi and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.01825},
  year={2023}
}

@article{shao2024deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}

@inproceedings{li2025raspberry,
  title={RASPberry: Retrieval-Augmented Monte Carlo Tree Self-Play with Reasoning Consistency for Multi-Hop Question Answering},
  author={Li, Baixuan and Fan, Yunlong and Ma, Tianyi and Gao, Miao and Shi, Chuanqi and Gao, Zhiqiang},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2025},
  pages={11258--11276},
  year={2025}
}

@article{chu2025sft,
  title={Sft memorizes, rl generalizes: A comparative study of foundation model post-training},
  author={Chu, Tianzhe and Zhai, Yuexiang and Yang, Jihan and Tong, Shengbang and Xie, Saining and Schuurmans, Dale and Le, Quoc V and Levine, Sergey and Ma, Yi},
  journal={arXiv preprint arXiv:2501.17161},
  year={2025}
}

@article{swamy2025all,
  title={All roads lead to likelihood: The value of reinforcement learning in fine-tuning},
  author={Swamy, Gokul and Choudhury, Sanjiban and Sun, Wen and Wu, Zhiwei Steven and Bagnell, J Andrew},
  journal={arXiv preprint arXiv:2503.01067},
  year={2025}
}

@article{yue2025does,
  title={Does reinforcement learning really incentivize reasoning capacity in llms beyond the base model?},
  author={Yue, Yang and Chen, Zhiqi and Lu, Rui and Zhao, Andrew and Wang, Zhaokai and Song, Shiji and Huang, Gao},
  journal={arXiv preprint arXiv:2504.13837},
  year={2025}
}

@article{ballon2025relationship,
  title={The Relationship Between Reasoning and Performance in Large Language Models--o3 (mini) Thinks Harder, Not Longer},
  author={Ballon, Marthe and Algaba, Andres and Ginis, Vincent},
  journal={arXiv preprint arXiv:2502.15631},
  year={2025}
}

@article{chen2023fireact,
  title={Fireact: Toward language agent fine-tuning},
  author={Chen, Baian and Shu, Chang and Shareghi, Ehsan and Collier, Nigel and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2310.05915},
  year={2023}
}


@article{gasteiger2018predict,
  title={Predict then propagate: Graph neural networks meet personalized pagerank},
  author={Gasteiger, Johannes and Bojchevski, Aleksandar and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:1810.05997},
  year={2018}
}

@inproceedings{moura2021lean,
  title={The lean 4 theorem prover and programming language},
  author={Moura, Leonardo de and Ullrich, Sebastian},
  booktitle={International Conference on Automated Deduction},
  pages={625--635},
  year={2021},
  organization={Springer}
}

@article{lovasz1993random,
  title={Random walks on graphs},
  author={Lov{\'a}sz, L{\'a}szl{\'o}},
  journal={Combinatorics, Paul erdos is eighty},
  volume={2},
  number={1-46},
  pages={4},
  year={1993}
}

@article{sun2024llm,
  title={Llm-based multi-agent reinforcement learning: Current and future directions},
  author={Sun, Chuanneng and Huang, Songjun and Pompili, Dario},
  journal={arXiv preprint arXiv:2405.11106},
  year={2024}
}

@article{jin2025search,
  title={Search-r1: Training llms to reason and leverage search engines with reinforcement learning},
  author={Jin, Bowen and Zeng, Hansi and Yue, Zhenrui and Yoon, Jinsung and Arik, Sercan and Wang, Dong and Zamani, Hamed and Han, Jiawei},
  journal={arXiv preprint arXiv:2503.09516},
  year={2025}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@misc{rewardhack,
  title = {Introducing OpenAI o3 and o4-mini},
  author = {OpenAI},
  url = {https://lilianweng.github.io/posts/2024-11-28-reward-hacking/},
  year={2025}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@inproceedings{DBLP:conf/coling/LiuYHZHWDSZ24,
  author       = {Yuxuan Liu and
                  Tianchi Yang and
                  Shaohan Huang and
                  Zihan Zhang and
                  Haizhen Huang and
                  Furu Wei and
                  Weiwei Deng and
                  Feng Sun and
                  Qi Zhang},
  editor       = {Nicoletta Calzolari and
                  Min{-}Yen Kan and
                  V{\'{e}}ronique Hoste and
                  Alessandro Lenci and
                  Sakriani Sakti and
                  Nianwen Xue},
  title        = {Calibrating LLM-Based Evaluator},
  booktitle    = {Proceedings of the 2024 Joint International Conference on Computational
                  Linguistics, Language Resources and Evaluation, {LREC/COLING} 2024,
                  20-25 May, 2024, Torino, Italy},
  pages        = {2638--2656},
  publisher    = {{ELRA} and {ICCL}},
  year         = {2024},
  url          = {https://aclanthology.org/2024.lrec-main.237},
  timestamp    = {Sun, 06 Oct 2024 20:58:36 +0200},
  biburl       = {https://dblp.org/rec/conf/coling/LiuYHZHWDSZ24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/emnlp/WangCCL0WYXZLLY24,
  author       = {Minzheng Wang and
                  Longze Chen and
                  Fu Cheng and
                  Shengyi Liao and
                  Xinghua Zhang and
                  Bingli Wu and
                  Haiyang Yu and
                  Nan Xu and
                  Lei Zhang and
                  Run Luo and
                  Yunshui Li and
                  Min Yang and
                  Fei Huang and
                  Yongbin Li},
  editor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {Leave No Document Behind: Benchmarking Long-Context LLMs with Extended
                  Multi-Doc {QA}},
  booktitle    = {Proceedings of the 2024 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2024, Miami, FL, USA, November 12-16,
                  2024},
  pages        = {5627--5646},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.emnlp-main.322},
  timestamp    = {Thu, 14 Nov 2024 17:20:55 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/WangCCL0WYXZLLY24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{sun2025climbing,
  title={Climbing the Ladder of Reasoning: What LLMs Can-and Still Can't-Solve after SFT?},
  author={Sun, Yiyou and Zhou, Georgia and Wang, Hao and Li, Dacheng and Dziri, Nouha and Song, Dawn},
  journal={arXiv preprint arXiv:2504.11741},
  year={2025}
}

@article{wiedemer2023compositional,
  title={Compositional generalization from first principles},
  author={Wiedemer, Thadd{\"a}us and Mayilvahanan, Prasanna and Bethge, Matthias and Brendel, Wieland},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={6941--6960},
  year={2023}
}

@article{kapoor2024large,
  title={Large Language Models Must Be Taught to Know What They Don't Know},
  author={Kapoor, Sanyam and Gruver, Nate and Roberts, Manley and Collins, Katherine and Pal, Arka and Bhatt, Umang and Weller, Adrian and Dooley, Samuel and Goldblum, Micah and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:2406.08391},
  year={2024}
}

@article{huang2023look,
  title={Look before you leap: An exploratory study of uncertainty measurement for large language models},
  author={Huang, Yuheng and Song, Jiayang and Wang, Zhijie and Zhao, Shengming and Chen, Huaming and Juefei-Xu, Felix and Ma, Lei},
  journal={arXiv preprint arXiv:2307.10236},
  year={2023}
}

@article{jurado2015measuring,
  title={Measuring uncertainty},
  author={Jurado, Kyle and Ludvigson, Sydney C and Ng, Serena},
  journal={American Economic Review},
  volume={105},
  number={3},
  pages={1177--1216},
  year={2015},
  publisher={American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203}
}

@article{ye2025limo,
  title={LIMO: Less is More for Reasoning},
  author={Ye, Yixin and Huang, Zhen and Xiao, Yang and Chern, Ethan and Xia, Shijie and Liu, Pengfei},
  journal={arXiv preprint arXiv:2502.03387},
  year={2025}
}

@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@inproceedings{sheng2025hybridflow,
  title={Hybridflow: A flexible and efficient rlhf framework},
  author={Sheng, Guangming and Zhang, Chi and Ye, Zilingfeng and Wu, Xibin and Zhang, Wang and Zhang, Ru and Peng, Yanghua and Lin, Haibin and Wu, Chuan},
  booktitle={Proceedings of the Twentieth European Conference on Computer Systems},
  pages={1279--1297},
  year={2025}
}

@article{kwiatkowski2019natural,
  title={Natural questions: a benchmark for question answering research},
  author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={453--466},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{joshi2017triviaqa,
  title={Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension},
  author={Joshi, Mandar and Choi, Eunsol and Weld, Daniel S and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1705.03551},
  year={2017}
}

@article{yang2018hotpotqa,
  title={HotpotQA: A dataset for diverse, explainable multi-hop question answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D},
  journal={arXiv preprint arXiv:1809.09600},
  year={2018}
}

@article{trivedi2022musique,
  title={MuSiQue: Multihop Questions via Single-hop Question Composition},
  author={Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={539--554},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{wei2024measuring,
  title={Measuring short-form factuality in large language models},
  author={Wei, Jason and Karina, Nguyen and Chung, Hyung Won and Jiao, Yunxin Joy and Papay, Spencer and Glaese, Amelia and Schulman, John and Fedus, William},
  journal={arXiv preprint arXiv:2411.04368},
  year={2024}
}

@misc{gpt4o,
  title = {Hello {GPT-4o}},
  author = {{OpenAI}},
  url = {https://openai.com/index/hello-gpt-4o/},
  year = {2024}
}

@article{li2025lara,
  title={LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs--No Silver Bullet for LC or RAG Routing},
  author={Li, Kuan and Zhang, Liwen and Jiang, Yong and Xie, Pengjun and Huang, Fei and Wang, Shuai and Cheng, Minhao},
  journal={arXiv preprint arXiv:2502.09977},
  year={2025}
}

@article{xu2019frequency,
  title={Frequency principle: Fourier analysis sheds light on deep neural networks},
  author={Xu, Zhi-Qin John and Zhang, Yaoyu and Luo, Tao and Xiao, Yanyang and Ma, Zheng},
  journal={arXiv preprint arXiv:1901.06523},
  year={2019}
}

@article{xu2024overview,
  title={Overview frequency principle/spectral bias in deep learning},
  author={Xu, Zhi-Qin John and Zhang, Yaoyu and Luo, Tao},
  journal={Communications on Applied Mathematics and Computation},
  pages={1--38},
  year={2024},
  publisher={Springer}
}
#
===================================================================分界线

@article{hoskin1996,
    title={The ``awful idea of accountability'': Inscribing people into the measurement of objects},
    author={Hoskin, Keith},
    year={1996},
    editor={Rolland Munro and Jan Mouritsen},
    journal={Accountability: Power, ethos and the technologies of managing}
}

@article{supergpqa,
  title={{SuperGPQA}: Scaling {LLM} evaluation across 285 graduate disciplines},
  author={Du, Xinrun and Yao, Yifan and Ma, Kaijing and Wang, Bingli and Zheng, Tianyu and Zhu, King and Liu, Minghao and Liang, Yiming and Jin, Xiaolong and Wei, Zhenlin and others},
  journal={arXiv preprint arXiv:2502.14739},
  year={2025}
}

@article{doremi,
  title={Doremi: Optimizing data mixtures speeds up language model pretraining},
  author={Xie, Sang Michael and Pham, Hieu and Dong, Xuanyi and Du, Nan and Liu, Hanxiao and Lu, Yifeng and Liang, Percy S and Le, Quoc V and Ma, Tengyu and Yu, Adams Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={69798--69818},
  year={2023}
}
@article{regmix,
  title={{RegMix}: Data mixture as regression for language model pre-training},
  author={Liu, Qian and Zheng, Xiaosen and Muennighoff, Niklas and Zeng, Guangtao and Dou, Longxu and Pang, Tianyu and Jiang, Jing and Lin, Min},
  journal={arXiv preprint arXiv:2407.01492},
  year={2024}
}

@article{doge,
  title={{DoGE}: Domain reweighting with generalization estimation},
  author={Fan, Simin and Pagliardini, Matteo and Jaggi, Martin},
  journal={arXiv preprint arXiv:2310.15393},
  year={2023}
}


@article{qwen2.5vl,
  title={{Qwen2.5-VL} technical report},
  author={Bai, Shuai and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Song, Sibo and Dang, Kai and Wang, Peng and Wang, Shijie and Tang, Jun and others},
  journal={arXiv preprint arXiv:2502.13923},
  year={2025}
}

@article{qwen2.5,
  title={Qwen2.5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@misc{Athene2024,
    title = {{Athene-70B}: Redefining the Boundaries of Post-Training for Open Models},
    url = {https://nexusflow.ai/blogs/athene},
    author = {Frick, Evan and Jin, Peter and Li, Tianle and Ganesan, Karthik and Zhang, Jian and Jiao, Jiantao and Zhu, Banghua},    
    month = {July},
    year = {2024}
}

@article{deepseekv3,
  title={{DeepSeek-V3} technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{glm4,
  title={Chatglm: A family of large language models from glm-130b to glm-4 all tools},
  author={GLM, Team and Zeng, Aohan and Xu, Bin and Wang, Bowen and Zhang, Chenhui and Yin, Da and Zhang, Dan and Rojas, Diego and Feng, Guanyu and Zhao, Hanlin and others},
  journal={arXiv preprint arXiv:2406.12793},
  year={2024}
}



@misc{llama4,
title={The {Llama} 4 herd: The beginning of a new era of natively multimodal {AI} innovation},
url={https://ai.meta.com/blog/llama-4-multimodal-intelligence/},
year={2025},
author={Meta-AI}}

@article{gemma3,
  title={Gemma 3 technical report},
  author={Team, Gemma and Kamath, Aishwarya and Ferret, Johan and Pathak, Shreya and Vieillard, Nino and Merhej, Ramona and Perrin, Sarah and Matejovicova, Tatiana and Ram{\'e}, Alexandre and Rivi{\`e}re, Morgane and others},
  journal={arXiv preprint arXiv:2503.19786},
  year={2025}
}
@article{Wang2024HelpSteer2PreferenceCR,
  title={{HelpSteer2-Preference}: Complementing Ratings with Preferences},
  author={Zhilin Wang and Alexander Bukharin and Olivier Delalleau and Daniel Egert and Gerald Shen and Jiaqi Zeng and Oleksii Kuchaiev and Yi Dong},
  journal={CoRR},
  year={2024},
  volume={abs/2410.01257}
}

@article{Adler2024Nemotron43T,
  title={Nemotron-4 {340B} Technical Report},
  author={Bo Adler and Niket Agarwal and Ashwath Aithal and Dong H. Anh and Pallab Bhattacharya and Annika Brundyn and Jared Casper and Bryan Catanzaro and Sharon Clay and Jonathan Cohen and Sirshak Das and Ayush Dattagupta and Olivier Delalleau and Leon Derczynski and Yi Dong and Daniel Egert and Ellie Evans and Aleksander Ficek and Denys Fridman and Shaona Ghosh and Boris Ginsburg and Igor Gitman and Tomasz Grzegorzek and Robert Hero and Jining Huang and Vibhu Jawa and Joseph Jennings and Aastha Jhunjhunwala and John Kamalu and Sadaf Khan and Oleksii Kuchaiev and Patrick LeGresley and Hui Li and Jiwei Liu and Zihan Liu and Eileen Peters Long and Ameya Mahabaleshwarkar and Somshubra Majumdar and James Maki and Miguel Martinez and Maer Rodrigues de Melo and Ivan Moshkov and Deepak Narayanan and Sean Narenthiran and Jesus Navarro and Phong Nguyen and Osvald Nitski and Vahid Noroozi and Guruprasad Nutheti and Christopher Parisien and Jupinder Parmar and Mostofa Patwary and Krzysztof Pawelec and Wei Ping and Shrimai Prabhumoye and Rajarshi Roy and Trisha Saar and Vasanth Rao Naik Sabavat and Sanjeev Satheesh and Jane Polak Scowcroft and Jason D. Sewall and Pavel Shamis and Gerald Shen and Mohammad Shoeybi and Dave Sizer and Misha Smelyanskiy and Felipe Soares and Makesh Narsimhan Sreedhar and Dan Su and Sandeep Subramanian and Shengyang Sun and Shubham Toshniwal and Hao Wang and Zhilin Wang and Jiaxuan You and Jiaqi Zeng and Jimmy Zhang and Jing Zhang and Vivienne Zhang and Yian Zhang and Chen Zhu},
  journal={CoRR},
  year={2024},
  volume={abs/2406.11704}
}
@article{Frick2024HowTE,
  title={How to Evaluate Reward Models for {RLHF}},
  author={Evan Frick and Tianle Li and Connor Chen and Wei-Lin Chiang and Anastasios Nikolas Angelopoulos and Jiantao Jiao and Banghua Zhu and Joseph E. Gonzalez and Ion Stoica},
  journal={CoRR},
  year={2024},
  volume={abs/2410.14872}
}
@article{Zhou2024RMBCB,
  title={{RMB}: Comprehensively Benchmarking Reward Models in {LLM} Alignment},
  author={Enyu Zhou and Guodong Zheng and Bing Wang and Zhiheng Xi and Shihan Dou and Rong Bao and Wei Shen and Limao Xiong and Jessica Fan and Yurong Mou and Rui Zheng and Tao Gui and Qi Zhang and Xuanjing Huang},
  journal={CoRR},
  year={2024},
  volume={abs/2410.09893}
}
@article{Lambert2024RewardBenchER,
  title={{RewardBench}: Evaluating Reward Models for Language Modeling},
  author={Nathan Lambert and Valentina Pyatkin and Jacob Daniel Morrison and Lester James Validad Miranda and Bill Yuchen Lin and Khyathi Raghavi Chandu and Nouha Dziri and Sachin Kumar and Tom Zick and Yejin Choi and Noah A. Smith and Hanna Hajishirzi},
  journal={CoRR},
  year={2024},
  volume={abs/2403.13787}
}

@article{palm,
  title={{PaLM}: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={CoRR},
  volume={abs/2204.02311},
  year={2022}
}

@article{yang2024evaluating,
  title={Evaluating and Aligning CodeLLMs on Human Preference},
  author={Yang, Jian and Yang, Jiaxi and Jin, Ke and Miao, Yibo and Zhang, Lei and Yang, Liqun and Cui, Zeyu and Zhang, Yichang and Hui, Binyuan and Lin, Junyang},
  journal={CoRR},
  volume={abs/2412.05210},
  year={2024}
}



@article{wang2024secrets,
  title={Secrets of {RLHF} in large language models Part {II}: Reward modeling},
  author={Wang, Binghai and Zheng, Rui and Chen, Lu and Liu, Yan and Dou, Shihan and Huang, Caishuang and Shen, Wei and Jin, Senjie and Zhou, Enyu and Shi, Chenyu and others},
  journal={CoRR},
  volume={abs/2401.06080},
  year={2024}
}

@article{dou2024multi,
  title={Multi-Programming Language Sandbox for LLMs},
  author={Dou, Shihan and Zhang, Jiazheng and Zang, Jianxiang and Tao, Yunbo and Jia, Haoxiang and Liu, Shichun and Yang, Yuming and Wu, Shenxi and Zhang, Shaoqing and Wu, Muling and others},
  journal={CoRR},
  volume={abs/2410.23074},
  year={2024}
}


@article{quan2024language,
  title={Language Models Can Self-Lengthen to Generate Long Texts},
  author={Quan, Shanghaoran and Tang, Tianyi and Yu, Bowen and Yang, An and Liu, Dayiheng and Gao, Bofei and Tu, Jianhong and Zhang, Yichang and Zhou, Jingren and Lin, Junyang},
  journal={CoRR},
  volume={abs/2410.23933},
  year={2024},
  archivePrefix={arXiv},
  eprint={2410.23933},
  primaryClass={cs.CL}
}


@article{xiang2024aligning,
  title={Aligning Large Language Models via Self-Steering Optimization},
  author={Xiang, Hao and Yu, Bowen and Lin, Hongyu and Lu, Keming and Lu, Yaojie and Han, Xianpei and Sun, Le and Zhou, Jingren and Lin, Junyang},
  journal={CoRR},
  volume={abs/2410.17131},
  year={2024}
}

@article{palm2,
  title={{PaLM} 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={CoRR},
  volume={abs/2305.10403},
  year={2023}
}

@article{qwen2,
  author       = {An Yang and
                  Baosong Yang and
                  Binyuan Hui and
                  Bo Zheng and
                  Bowen Yu and
                  Chang Zhou and
                  Chengpeng Li and
                  Chengyuan Li and
                  Dayiheng Liu and
                  Fei Huang and
                  Guanting Dong and
                  Haoran Wei and
                  Huan Lin and
                  Jialong Tang and
                  Jialin Wang and
                  Jian Yang and
                  Jianhong Tu and
                  Jianwei Zhang and
                  Jianxin Ma and
                  Jianxin Yang and
                  Jin Xu and
                  Jingren Zhou and
                  Jinze Bai and
                  Jinzheng He and
                  Junyang Lin and
                  Kai Dang and
                  Keming Lu and
                  Keqin Chen and
                  Kexin Yang and
                  Mei Li and
                  Mingfeng Xue and
                  Na Ni and
                  Pei Zhang and
                  Peng Wang and
                  Ru Peng and
                  Rui Men and
                  Ruize Gao and
                  Runji Lin and
                  Shijie Wang and
                  Shuai Bai and
                  Sinan Tan and
                  Tianhang Zhu and
                  Tianhao Li and
                  Tianyu Liu and
                  Wenbin Ge and
                  Xiaodong Deng and
                  Xiaohuan Zhou and
                  Xingzhang Ren and
                  Xinyu Zhang and
                  Xipin Wei and
                  Xuancheng Ren and
                  Xuejing Liu and
                  Yang Fan and
                  Yang Yao and
                  Yichang Zhang and
                  Yu Wan and
                  Yunfei Chu and
                  Yuqiong Liu and
                  Zeyu Cui and
                  Zhenru Zhang and
                  Zhifang Guo and
                  Zhihao Fan},
  title        = {Qwen2 Technical Report},
  journal      = {CoRR},
  volume       = {abs/2407.10671},
  year         = {2024}
}

@inproceedings{rafailov2024direct,
  author       = {Rafael Rafailov and
                  Archit Sharma and
                  Eric Mitchell and
                  Christopher D. Manning and
                  Stefano Ermon and
                  Chelsea Finn},
  title        = {Direct Preference Optimization: Your Language Model is Secretly a
                  Reward Model},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{lu2024online,
  author       = {Keming Lu and
                  Bowen Yu and
                  Fei Huang and
                  Yang Fan and
                  Runji Lin and
                  Chang Zhou},
  title        = {Online Merging Optimizers for Boosting Rewards and Mitigating Tax
                  in Alignment},
  journal      = {CoRR},
  volume       = {abs/2405.17931},
  year         = {2024}
}

@article{bai2022constitutional,
author       = {Yuntao Bai and
                  Saurav Kadavath and
                  Sandipan Kundu and
                  Amanda Askell and
                  Jackson Kernion and
                  Andy Jones and
                  Anna Chen and
                  Anna Goldie and
                  Azalia Mirhoseini and
                  Cameron McKinnon and
                  Carol Chen and
                  Catherine Olsson and
                  Christopher Olah and
                  Danny Hernandez and
                  Dawn Drain and
                  Deep Ganguli and
                  Dustin Li and
                  Eli Tran{-}Johnson and
                  Ethan Perez and
                  Jamie Kerr and
                  Jared Mueller and
                  Jeffrey Ladish and
                  Joshua Landau and
                  Kamal Ndousse and
                  Kamile Lukosiute and
                  Liane Lovitt and
                  Michael Sellitto and
                  Nelson Elhage and
                  Nicholas Schiefer and
                  Noem{\'{\i}} Mercado and
                  Nova DasSarma and
                  Robert Lasenby and
                  Robin Larson and
                  Sam Ringer and
                  Scott Johnston and
                  Shauna Kravec and
                  Sheer El Showk and
                  Stanislav Fort and
                  Tamera Lanham and
                  Timothy Telleen{-}Lawton and
                  Tom Conerly and
                  Tom Henighan and
                  Tristan Hume and
                  Samuel R. Bowman and
                  Zac Hatfield{-}Dodds and
                  Ben Mann and
                  Dario Amodei and
                  Nicholas Joseph and
                  Sam McCandlish and
                  Tom Brown and
                  Jared Kaplan},
  title        = {Constitutional {AI}: Harmlessness from {AI} Feedback},
  journal      = {CoRR},
  volume       = {abs/2212.08073},
  year         = {2022}
}

@article{cao2024towards,
  author       = {Boxi Cao and
                  Keming Lu and
                  Xinyu Lu and
                  Jiawei Chen and
                  Mengjie Ren and
                  Hao Xiang and
                  Peilin Liu and
                  Yaojie Lu and
                  Ben He and
                  Xianpei Han and
                  Le Sun and
                  Hongyu Lin and
                  Bowen Yu},
  title        = {Towards Scalable Automated Alignment of {LLMs}: A Survey},
  journal      = {CoRR},
  volume       = {abs/2406.01252},
  year         = {2024}
}

@article{lu2024large,
  author       = {Keming Lu and
                  Bowen Yu and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {Large Language Models are Superpositions of All Characters: Attaining
                  Arbitrary Role-play via Self-Alignment},
  journal      = {CoRR},
  volume       = {abs/2401.12474},
  year         = {2024}
}

@article{dong2024autoif,
  title={Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models},
  author={Dong, Guanting and Lu, Keming and Li, Chengpeng and Xia, Tingyu and Yu, Bowen and Zhou, Chang and Zhou, Jingren},
  journal={CoRR},
  volume={abs/2406.13542},
  year={2024}
}

@article{ext5,
  title={{ExT5}: Towards extreme multi-task scaling for transfer learning},
  author={Aribandi, Vamsi and Tay, Yi and Schuster, Tal and Rao, Jinfeng and Zheng, Huaixiu Steven and Mehta, Sanket Vaibhav and Zhuang, Honglei and Tran, Vinh Q and Bahri, Dara and Ni, Jianmo and others},
  journal={CoRR},
  volume={abs/2111.10952},
  year={2021}
}

@article{pmmeval,
  title={{P-MMEval}: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of {LLMs}},
  author={Zhang, Yidan and Deng, Boyi and Wan, Yu and Yang, Baosong and Wei, Haoran and Huang, Fei and Yu, Bowen and Lin, Junyang and Zhou, Jingren},
  journal={CoRR},
  volume={abs/2411.09116},
  year={2024}
}

@article{dong2023abilities,
  author       = {Guanting Dong and
                  Hongyi Yuan and
                  Keming Lu and
                  Chengpeng Li and
                  Mingfeng Xue and
                  Dayiheng Liu and
                  Wei Wang and
                  Zheng Yuan and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {How Abilities in Large Language Models are Affected by Supervised
                  Fine-tuning Data Composition},
  journal      = {CoRR},
  volume       = {abs/2310.05492},
  year         = {2023}
}

@inproceedings{zhao2024tree,
  author       = {Yingxiu Zhao and
                  Bowen Yu and
                  Binyuan Hui and
                  Haiyang Yu and
                  Minghao Li and
                  Fei Huang and
                  Nevin L. Zhang and
                  Yongbin Li},
  title        = {{Tree-Instruct}: {A} Preliminary Study of the Intrinsic Relationship
                  between Complexity and Alignment},
  booktitle    = {{LREC/COLING}},
  pages        = {16776--16789},
  publisher    = {{ELRA} and {ICCL}},
  year         = {2024}
}

@inproceedings{lu2023instag,
  title={\#{InsTag}: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models},
  author={Lu, Keming and Yuan, Hongyi and Yuan, Zheng and Lin, Runji and Lin, Junyang and Tan, Chuanqi and Zhou, Chang and Zhou, Jingren},
  booktitle={{ICLR}},
  publisher    = {OpenReview.net},
  year={2024}
}


@article{polylm,
  title={{PolyLM}: An open source polyglot large language model},
  author={Wei, Xiangpeng and Wei, Haoran and Lin, Huan and Li, Tianhao and Zhang, Pei and Ren, Xingzhang and Li, Mei and Wan, Yu and Cao, Zhiwei and Xie, Binbin and others},
  journal={CoRR},
  volume={abs/2307.06018},
  year={2023}
}

@article{refineweb,
  title={The {RefinedWeb} dataset for {Falcon} {LLM}: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={CoRR},
  volume={abs/2306.01116},
  year={2023}
}

@misc{bard,
  title = {An important next step on our {AI} journey},
  author = {Google},
  url = {https://blog.google/technology/ai/bard-google-ai-search-updates/},
  year={2023}
}

@misc{opencompass,
  title = {{OpenCompass}: A universal evaluation platform for foundation models},
  author = {{OpenCompass Contributors}},
  url = {https://github.com/open-compass/opencompass},
  year={2023}
}

@misc{chatml,
  title = {{ChatML}},
  author = {{OpenAI}},
  url = {https://github.com/openai/openai-python/blob/e389823ba013a24b4c32ce38fa0bd87e6bccae94/chatml.md},
  year = {2022}
}

@misc{code_interpreter,
  title = {{ChatGPT plugins}},
  author = {{OpenAI}},
  url = {https://openai.com/blog/chatgpt-plugins},
  year = {2023}
}

@article{xlmr,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={CoRR},
  volume={abs/1911.02116},
  year={2019}
}

@inproceedings{singla2024dynamic,
  author       = {Somanshu Singla and
                  Zhen Wang and
                  Tianyang Liu and
                  Abdullah Ashfaq and
                  Zhiting Hu and
                  Eric P. Xing},
  title        = {Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment
                  of Language Models},
  booktitle    = {{EMNLP}},
  pages        = {21889--21909},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@misc{StableBeluga2,
  title = {{StableBeluga2}},
  author = {{Stability AI}},
  url = {https://huggingface.co/stabilityai/StableBeluga2},
  year = {2023}
}


@misc{qwen-tool-eval,
  title = {Evaluation Benchmark for Tool Usage through {ReAct} Prompting},
  author = {{Qwen~Team, Alibaba Group}},
  url = {https:
//github.com/QwenLM/Qwen-7B/tree/main/eval},
  year = {2023}
}

@article{code_llama,
  title={Code {Llama}: Open foundation models for code},
  author={Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={CoRR},
  volume={abs/2308.12950},
  year={2023}
}

@misc{qwen-code-interpreter-eval,
  title = {Evaluation Benchmark for Code Intepreter},
  author = {{Qwen~Team}},
  url = { https:
//github.com/QwenLM/Qwen-Agent/tree/main/benchmark},
  year = {2023}
}


@misc{claude,
  title = {Introducing {Claude}},
  author = {Anthropic},
  institution = {Anthropic},
  url = {https://www.anthropic.com/index/introducing-claude},
  year={2023}
}


@techreport{claude2,
  title = {Claude 2},
  author = {Anthropic},
  institution = {Anthropic},
  url = {https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf},
  year={2023}
}

@article{phi4,
  title={Phi-4 technical report},
  author={Abdin, Marah and Aneja, Jyoti and Behl, Harkirat and Bubeck, S{\'e}bastien and Eldan, Ronen and Gunasekar, Suriya and Harrison, Michael and Hewett, Russell J and Javaheripi, Mojan and Kauffmann, Piero and others},
  journal={arXiv preprint arXiv:2412.08905},
  year={2024}
}

@misc{langchain,
    title = {{LangChain}: Building applications with {LLMs} through composability},
    author = {{LangChain, Inc.}},
    url = {https://python.langchain.com/},
    year = {2023}
}

@article{rope,
  author       = {Jianlin Su and
                  Murtadha H. M. Ahmed and
                  Yu Lu and
                  Shengfeng Pan and
                  Wen Bo and
                  Yunfeng Liu},
  title        = {RoFormer: Enhanced {Transformer} with Rotary Position Embedding},
  journal      = {Neurocomputing},
  volume       = {568},
  pages        = {127063},
  year         = {2024}
}

@misc{qwen1.5,
    title = {Introducing {Qwen1.5}},
    url = {https://qwenlm.github.io/blog/qwen1.5/},
    author = {{Qwen~Team}},
    year = {2024}
}

@inproceedings{bostrom2020byte,
    title = "Byte Pair Encoding is Suboptimal for Language Model Pretraining",
    author = "Bostrom, Kaj  and
      Durrett, Greg",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.414",
    doi = "10.18653/v1/2020.findings-emnlp.414",
    pages = "4617--4624",
    abstract = "The success of pretrained transformer language models (LMs) in natural language processing has led to a wide range of pretraining setups. In particular, these models employ a variety of subword tokenization methods, most notably byte-pair encoding (BPE) (Sennrich et al., 2016; Gage, 1994), the WordPiece method (Schuster and Nakajima, 2012), and unigram language modeling (Kudo, 2018), to segment text. However, to the best of our knowledge, the literature does not contain a direct evaluation of the impact of tokenization on language model pretraining. We analyze differences between BPE and unigram LM tokenization, finding that the latter method recovers subword units that align more closely with morphology and avoids problems stemming from BPE{'}s greedy construction procedure. We then compare the fine-tuned task performance of identical transformer masked language models pretrained with these tokenizations. Across downstream tasks and two languages (English and Japanese), we find that the unigram LM tokenization method matches or outperforms BPE. We hope that developers of future pretrained LMs will consider adopting the unigram LM method over the more prevalent BPE.",
}

@inproceedings{gpt3,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  title        = {Language Models are Few-Shot Learners},
  booktitle    = {NeurIPS},
  year         = {2020}
}

@article{llama,
  title={{LLaMA}: Open and efficient foundation language models},
  author       = {Hugo Touvron and
                  Thibaut Lavril and
                  Gautier Izacard and
                  Xavier Martinet and
                  Marie{-}Anne Lachaux and
                  Timoth{\'{e}}e Lacroix and
                  Baptiste Rozi{\`{e}}re and
                  Naman Goyal and
                  Eric Hambro and
                  Faisal Azhar and
                  Aur{\'{e}}lien Rodriguez and
                  Armand Joulin and
                  Edouard Grave and
                  Guillaume Lample},
  journal      = {CoRR},
  volume       = {abs/2302.13971},
  year         = {2023}
}

@article{llama2,
  author       = {Hugo Touvron and
                  Louis Martin and
                  Kevin Stone and
                  Peter Albert and
                  Amjad Almahairi and
                  Yasmine Babaei and
                  Nikolay Bashlykov and
                  Soumya Batra and
                  Prajjwal Bhargava and
                  Shruti Bhosale and
                  Dan Bikel and
                  Lukas Blecher and
                  Cristian Canton{-}Ferrer and
                  Moya Chen and
                  Guillem Cucurull and
                  David Esiobu and
                  Jude Fernandes and
                  Jeremy Fu and
                  Wenyin Fu and
                  Brian Fuller and
                  Cynthia Gao and
                  Vedanuj Goswami and
                  Naman Goyal and
                  Anthony Hartshorn and
                  Saghar Hosseini and
                  Rui Hou and
                  Hakan Inan and
                  Marcin Kardas and
                  Viktor Kerkez and
                  Madian Khabsa and
                  Isabel Kloumann and
                  Artem Korenev and
                  Punit Singh Koura and
                  Marie{-}Anne Lachaux and
                  Thibaut Lavril and
                  Jenya Lee and
                  Diana Liskovich and
                  Yinghai Lu and
                  Yuning Mao and
                  Xavier Martinet and
                  Todor Mihaylov and
                  Pushkar Mishra and
                  Igor Molybog and
                  Yixin Nie and
                  Andrew Poulton and
                  Jeremy Reizenstein and
                  Rashi Rungta and
                  Kalyan Saladi and
                  Alan Schelten and
                  Ruan Silva and
                  Eric Michael Smith and
                  Ranjan Subramanian and
                  Xiaoqing Ellen Tan and
                  Binh Tang and
                  Ross Taylor and
                  Adina Williams and
                  Jian Xiang Kuan and
                  Puxin Xu and
                  Zheng Yan and
                  Iliyan Zarov and
                  Yuchen Zhang and
                  Angela Fan and
                  Melanie Kambadur and
                  Sharan Narang and
                  Aur{\'{e}}lien Rodriguez and
                  Robert Stojnic and
                  Sergey Edunov and
                  Thomas Scialom},
  title        = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  journal      = {CoRR},
  volume       = {abs/2307.09288},
  year         = {2023}
}

@article{layer_norm,
  author       = {Lei Jimmy Ba and
                  Jamie Ryan Kiros and
                  Geoffrey E. Hinton},
  title        = {Layer Normalization},
  journal      = {CoRR},
  volume       = {abs/1607.06450},
  year         = {2016},
  url          = {http://arxiv.org/abs/1607.06450},
  eprinttype    = {arXiv},
  eprint       = {1607.06450},
  timestamp    = {Tue, 23 Jul 2019 17:33:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/BaKH16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{rmsnorm,
  author       = {Zixuan Jiang and
                  Jiaqi Gu and
                  Hanqing Zhu and
                  David Z. Pan},
  title        = {{Pre-RMSNorm} and {Pre-CRMSNorm} {Transformers}: Equivalent and Efficient
                  Pre-{LN} {Transformers}},
  journal      = {CoRR},
  volume       = {abs/2305.14858},
  year         = {2023}
}

@article{geglu,
  author       = {Noam Shazeer},
  title        = {{GLU} Variants Improve Transformer},
  journal      = {CoRR},
  volume       = {abs/2002.05202},
  year         = {2020},
  url          = {https://arxiv.org/abs/2002.05202},
  eprinttype    = {arXiv},
  eprint       = {2002.05202},
  timestamp    = {Fri, 14 Feb 2020 12:07:41 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2002-05202.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gelu,
  author       = {Dan Hendrycks and
                  Kevin Gimpel},
  title        = {Bridging Nonlinearities and Stochastic Regularizers with {Gaussian}
                  Error Linear Units},
  journal      = {CoRR},
  volume       = {abs/1606.08415},
  year         = {2016},
  url          = {http://arxiv.org/abs/1606.08415},
  eprinttype    = {arXiv},
  eprint       = {1606.08415},
  timestamp    = {Mon, 13 Aug 2018 16:46:20 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/HendrycksG16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{glu,
  author       = {Yann N. Dauphin and
                  Angela Fan and
                  Michael Auli and
                  David Grangier},
  title        = {Language Modeling with Gated Convolutional Networks},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {70},
  pages        = {933--941},
  publisher    = {{PMLR}},
  year         = {2017}
}

@article{noamglu,
  title={{GLU} variants improve transformer},
  author={Shazeer, Noam},
  journal={CoRR},
  volume={abs/2002.05202},
  year={2020}
}

@article{swish,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={CoRR},
  volume={abs/1710.05941},
  year={2017}
}

@article{gpt4,
  title={{GPT4} technical report},
  author={{OpenAI}},
  journal={CoRR},
  volume={abs/2303.08774},
  year={2023}
}

@misc{tiktoken,
   title = {{tiktoken}: A fast {BPE} tokeniser for use with {OpenAI}'s models},
   author = {Shantanu Jain},
   institution = {OpenAI},
   year = {2022},
   url = {https://github.com/openai/tiktoken/}
}

@inproceedings{flashattn,
  author       = {Tri Dao and
                  Daniel Y. Fu and
                  Stefano Ermon and
                  Atri Rudra and
                  Christopher R{\'{e}}},
  title        = {{FlashAttention}: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/67d57c32e20fd0a7a302cb81d36e40d5-Abstract-Conference.html},
  timestamp    = {Thu, 11 May 2023 17:08:21 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/DaoFERR22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{transformer,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention is All you Need},
  booktitle    = {{NIPS}},
  pages        = {5998--6008},
  year         = {2017}
}

@article{roberta,
  title={{RoBERTa}: A robustly optimized {BERT} pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={CoRR},
  volume={abs/1907.11692},
  year={2019}
}



@inproceedings{flan,
  author       = {Jason Wei and
                  Maarten Bosma and
                  Vincent Y. Zhao and
                  Kelvin Guu and
                  Adams Wei Yu and
                  Brian Lester and
                  Nan Du and
                  Andrew M. Dai and
                  Quoc V. Le},
  title        = {Finetuned Language Models are Zero-Shot Learners},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=gEZrGCozdqR},
  timestamp    = {Wed, 16 Aug 2023 16:10:28 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/WeiBZGYLDDL22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{flanv2,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={CoRR},
  volume={abs/2210.11416},
  year={2022}
}

@article{flan-collection,
  title={The {Flan} collection: Designing data and methods for effective instruction tuning},
  author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  journal={CoRR},
  volume={abs/2301.13688},
  year={2023}
}

@misc{codeqwen1.5,
    title = {Code with CodeQwen1.5},
    url = {https://qwenlm.github.io/blog/codeqwen1.5/},
    author = {{Qwen~Team}},
    month = {April},
    year = {2024}
}

@article{cai,
  title={Constitutional {AI}: Harmlessness from {AI} feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={CoRR},
  volume={abs/2212.08073},
  year={2022}
}

@inproceedings{rlhf,
  author       = {Paul F. Christiano and
                  Jan Leike and
                  Tom B. Brown and
                  Miljan Martic and
                  Shane Legg and
                  Dario Amodei},
  editor       = {Isabelle Guyon and
                  Ulrike von Luxburg and
                  Samy Bengio and
                  Hanna M. Wallach and
                  Rob Fergus and
                  S. V. N. Vishwanathan and
                  Roman Garnett},
  title        = {Deep Reinforcement Learning from Human Preferences},
  booktitle    = {Advances in Neural Information Processing Systems 30: Annual Conference
                  on Neural Information Processing Systems 2017, December 4-9, 2017,
                  Long Beach, CA, {USA}},
  pages        = {4299--4307},
  year         = {2017},
  url          = {https://proceedings.neurips.cc/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html},
  timestamp    = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/ChristianoLBMLA17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{red-teaming,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={CoRR},
  volume={abs/2209.07858},
  year={2022}
}

@misc{transformers-agents,
    title = {Transformers Agents},
    author = {{Hugging Face}},
    url = {https://huggingface.co/docs/transformers/transformers_agents}, 
    year = {2023}
}


@misc{qwen1.5moe,
    title = {{Qwen1.5-MoE}: Matching {7B} Model Performance with 1/3 Activated Parameters},
    url = {https://qwenlm.github.io/blog/qwen-moe/},
    author = {{Qwen~Team}},
    year = {2024}
}

@article{thestack,
  author       = {Denis Kocetkov and
                  Raymond Li and
                  Loubna Ben Allal and
                  Jia Li and
                  Chenghao Mou and
                  Carlos Mu{\~{n}}oz Ferrandis and
                  Yacine Jernite and
                  Margaret Mitchell and
                  Sean Hughes and
                  Thomas Wolf and
                  Dzmitry Bahdanau and
                  Leandro von Werra and
                  Harm de Vries},
  title        = {The Stack: 3 {TB} of permissively licensed source code},
  journal      = {CoRR},
  volume       = {abs/2211.15533},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2211.15533},
  doi          = {10.48550/arXiv.2211.15533},
  eprinttype    = {arXiv},
  eprint       = {2211.15533},
  timestamp    = {Tue, 29 Nov 2022 17:41:18 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2211-15533.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{codeparrot-github-clean,
title = {{GitHub} Code Dataset Cleaned},
author = {{CodeParrot}},
url = {https://huggingface.co/datasets/codeparrot/github-code-clean},
year = {2022}
}

@article{starcoder,
  author       = {Raymond Li and
                  Loubna Ben Allal and
                  Yangtian Zi and
                  Niklas Muennighoff and
                  Denis Kocetkov and
                  Chenghao Mou and
                  Marc Marone and
                  Christopher Akiki and
                  Jia Li and
                  Jenny Chim and
                  Qian Liu and
                  Evgenii Zheltonozhskii and
                  Terry Yue Zhuo and
                  Thomas Wang and
                  Olivier Dehaene and
                  Mishig Davaadorj and
                  Joel Lamy{-}Poirier and
                  Jo{\~{a}}o Monteiro and
                  Oleh Shliazhko and
                  Nicolas Gontier and
                  Nicholas Meade and
                  Armel Zebaze and
                  Ming{-}Ho Yee and
                  Logesh Kumar Umapathi and
                  Jian Zhu and
                  Benjamin Lipkin and
                  Muhtasham Oblokulov and
                  Zhiruo Wang and
                  Rudra Murthy V and
                  Jason Stillerman and
                  Siva Sankalp Patel and
                  Dmitry Abulkhanov and
                  Marco Zocca and
                  Manan Dey and
                  Zhihan Zhang and
                  Nour Moustafa{-}Fahmy and
                  Urvashi Bhattacharyya and
                  Wenhao Yu and
                  Swayam Singh and
                  Sasha Luccioni and
                  Paulo Villegas and
                  Maxim Kunakov and
                  Fedor Zhdanov and
                  Manuel Romero and
                  Tony Lee and
                  Nadav Timor and
                  Jennifer Ding and
                  Claire Schlesinger and
                  Hailey Schoelkopf and
                  Jan Ebert and
                  Tri Dao and
                  Mayank Mishra and
                  Alex Gu and
                  Jennifer Robinson and
                  Carolyn Jane Anderson and
                  Brendan Dolan{-}Gavitt and
                  Danish Contractor and
                  Siva Reddy and
                  Daniel Fried and
                  Dzmitry Bahdanau and
                  Yacine Jernite and
                  Carlos Mu{\~{n}}oz Ferrandis and
                  Sean Hughes and
                  Thomas Wolf and
                  Arjun Guha and
                  Leandro von Werra and
                  Harm de Vries},
  title        = {{StarCoder}: May the source be with you!},
  journal      = {CoRR},
  volume       = {abs/2305.06161},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.06161},
  doi          = {10.48550/arXiv.2305.06161},
  eprinttype    = {arXiv},
  eprint       = {2305.06161},
  timestamp    = {Fri, 23 Jun 2023 22:30:55 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-06161.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{generalist,
  author       = {Scott E. Reed and
                  Konrad Zolna and
                  Emilio Parisotto and
                  Sergio G{\'{o}}mez Colmenarejo and
                  Alexander Novikov and
                  Gabriel Barth{-}Maron and
                  Mai Gimenez and
                  Yury Sulsky and
                  Jackie Kay and
                  Jost Tobias Springenberg and
                  Tom Eccles and
                  Jake Bruce and
                  Ali Razavi and
                  Ashley Edwards and
                  Nicolas Heess and
                  Yutian Chen and
                  Raia Hadsell and
                  Oriol Vinyals and
                  Mahyar Bordbar and
                  Nando de Freitas},
  title        = {A Generalist Agent},
  journal      = {Trans. Mach. Learn. Res.},
  volume       = {2022},
  year         = {2022},
  url          = {https://openreview.net/forum?id=1ikK0kHjvj},
  timestamp    = {Fri, 19 May 2023 11:20:41 +0200},
  biburl       = {https://dblp.org/rec/journals/tmlr/ReedZPCNBGSKSEBREHCHVBF22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gemma2,
  title={Gemma 2: Improving open language models at a practical size},
  author={{Gemma Team} and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={CoRR},
  volume={abs/2408.00118},
  year={2024}
}

@article{mmluredux,
  title={Are We Done with {MMLU}?},
  author={Gema, Aryo Pradipta and Leang, Joshua Ong Jun and Hong, Giwon and Devoto, Alessio and Mancino, Alberto Carlo Maria and Saxena, Rohit and He, Xuanli and Zhao, Yu and Du, Xiaotang and Madani, Mohammad Reza Ghasemi and others},
  journal={CoRR},
  volume={abs/2406.04127},
  year={2024}
}

@misc{chatgpt,
    title = {Introducing {ChatGPT}} ,
    author = {{OpenAI}},
    url = {https://openai.com/index/chatgpt/},
    year = {2022}
}

@inproceedings{instructgpt,
  author       = {Long Ouyang and
                  Jeffrey Wu and
                  Xu Jiang and
                  Diogo Almeida and
                  Carroll L. Wainwright and
                  Pamela Mishkin and
                  Chong Zhang and
                  Sandhini Agarwal and
                  Katarina Slama and
                  Alex Ray and
                  John Schulman and
                  Jacob Hilton and
                  Fraser Kelton and
                  Luke Miller and
                  Maddie Simens and
                  Amanda Askell and
                  Peter Welinder and
                  Paul F. Christiano and
                  Jan Leike and
                  Ryan Lowe},
  title        = {Training language models to follow instructions with human feedback},
  booktitle    = {NeurIPS},
  year         = {2022},
  timestamp    = {Thu, 11 May 2023 17:08:21 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/Ouyang0JAWMZASR22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{wolfe2024laboratory,
  author       = {Robert Wolfe and
                  Isaac Slaughter and
                  Bin Han and
                  Bingbing Wen and
                  Yiwei Yang and
                  Lucas Rosenblatt and
                  Bernease Herman and
                  Eva Maxfield Brown and
                  Zening Qu and
                  Nic Weber and
                  Bill Howe},
  title        = {Laboratory-Scale {AI:} Open-Weight Models are Competitive with {ChatGPT}
                  Even in Low-Resource Settings},
  booktitle    = {FAccT},
  pages        = {1199--1210},
  publisher    = {{ACM}},
  year         = {2024}
}

@inproceedings{kapoor2024societal,
  author       = {Sayash Kapoor and
                  Rishi Bommasani and
                  Kevin Klyman and
                  Shayne Longpre and
                  Ashwin Ramaswami and
                  Peter Cihon and
                  Aspen K. Hopkins and
                  Kevin Bankston and
                  Stella Biderman and
                  Miranda Bogen and
                  Rumman Chowdhury and
                  Alex Engler and
                  Peter Henderson and
                  Yacine Jernite and
                  Seth Lazar and
                  Stefano Maffulli and
                  Alondra Nelson and
                  Joelle Pineau and
                  Aviya Skowron and
                  Dawn Song and
                  Victor Storchan and
                  Daniel Zhang and
                  Daniel E. Ho and
                  Percy Liang and
                  Arvind Narayanan},
  title        = {Position: On the Societal Impact of Open Foundation Models},
  booktitle    = {{ICML}},
  publisher    = {OpenReview.net},
  year         = {2024}
}

@article{qwen2.5coder,
  title={{Qwen2.5-Coder} technical report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Lu, Keming and others},
  journal={CoRR},
  volume={abs/2409.12186},
  year={2024}
}


@misc{qwen2math,
  title={{Introducing Qwen2-Math}},
  author={{Qwen~Team}},
  year={2024},
  url={https://qwenlm.github.io/blog/qwen2-math/}
}

@article{qwen2.5math,
  title={{Qwen2.5-Math} technical report: Toward mathematical expert model via self-improvement},
  author={Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others},
  journal={CoRR},
  volume={abs/2409.12122},
  year={2024}
}

@article{kaplanscaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={CoRR},
  volume={abs/2001.08361},
  year={2020}
}

@article{chinchilla,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={CoRR},
  volume={abs/2203.15556},
  year={2022}
}

@article{scaling_rush,
  title={Scaling Data-Constrained Language Models},
  author={Muennighoff, Niklas and Rush, Alexander M and Barak, Boaz and Scao, Teven Le and Piktus, Aleksandra and Tazi, Nouamane and Pyysalo, Sampo and Wolf, Thomas and Raffel, Colin},
  journal={CoRR},
  volume={abs/2305.16264},
  year={2023}
}


@inproceedings{mmlu,
  author       = {Dan Hendrycks and
                  Collin Burns and
                  Steven Basart and
                  Andy Zou and
                  Mantas Mazeika and
                  Dawn Song and
                  Jacob Steinhardt},
  title        = {Measuring Massive Multitask Language Understanding},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2021}
}

@inproceedings{bbh,
  author       = {Mirac Suzgun and
                  Nathan Scales and
                  Nathanael Sch{\"{a}}rli and
                  Sebastian Gehrmann and
                  Yi Tay and
                  Hyung Won Chung and
                  Aakanksha Chowdhery and
                  Quoc V. Le and
                  Ed H. Chi and
                  Denny Zhou and
                  Jason Wei},
  title        = {Challenging {BIG-Bench} Tasks and Whether Chain-of-Thought Can Solve
                  Them},
  booktitle    = {{ACL} (Findings)},
  pages        = {13003--13051},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{mbpp,
  author       = {Jacob Austin and
                  Augustus Odena and
                  Maxwell I. Nye and
                  Maarten Bosma and
                  Henryk Michalewski and
                  David Dohan and
                  Ellen Jiang and
                  Carrie J. Cai and
                  Michael Terry and
                  Quoc V. Le and
                  Charles Sutton},
  title        = {Program Synthesis with Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2108.07732},
  year         = {2021}
}

@article{cmmlu,
  author       = {Haonan Li and
                  Yixuan Zhang and
                  Fajri Koto and
                  Yifei Yang and
                  Hai Zhao and
                  Yeyun Gong and
                  Nan Duan and
                  Timothy Baldwin},
  title        = {{CMMLU}: Measuring massive multitask language understanding in {Chinese}},
  journal      = {CoRR},
  volume       = {abs/2306.09212},
  year         = {2023}
}

@inproceedings{ceval,
  author       = {Yuzhen Huang and
                  Yuzhuo Bai and
                  Zhihao Zhu and
                  Junlei Zhang and
                  Jinghan Zhang and
                  Tangjun Su and
                  Junteng Liu and
                  Chuancheng Lv and
                  Yikai Zhang and
                  Jiayi Lei and
                  Yao Fu and
                  Maosong Sun and
                  Junxian He},
  title        = {{C-Eval}: A Multi-Level Multi-Discipline Chinese Evaluation Suite
                  for Foundation Models},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{gsm8k,
  author       = {Karl Cobbe and
                  Vineet Kosaraju and
                  Mohammad Bavarian and
                  Mark Chen and
                  Heewoo Jun and
                  Lukasz Kaiser and
                  Matthias Plappert and
                  Jerry Tworek and
                  Jacob Hilton and
                  Reiichiro Nakano and
                  Christopher Hesse and
                  John Schulman},
  title        = {Training Verifiers to Solve Math Word Problems},
  journal      = {CoRR},
  volume       = {abs/2110.14168},
  year         = {2021}
}


@article{pile,
  title={The {Pile}: An {800GB} dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={CoRR},
  volume={abs/2101.00027},
  year={2020}
}



@article{t5,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={CoRR},
  volume={abs/2304.08485},
  year={2023}
}

@article{instructblip,
  title={{InstructBLIP}: Towards General-purpose Vision-Language Models with Instruction Tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Meng, Anthony and  Tiong, Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale and Hoi, Steven},
  journal={CoRR},
  volume={abs/2305.06500},
  year={2023}
}

@article{kosmos2,
  title={Kosmos-2: Grounding Multimodal Large Language Models to the World},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Wei, Furu},
  journal={CoRR},
  volume={abs/2306.14824},
  year={2023}
}

@article{toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={CoRR},
  volume={abs/2302.04761},
  year={2023}
}

@article{megatron,
  title={{Megatron-LM}: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={CoRR},
  volume={abs/1909.08053},
  year={2019}
}

@article{bloom,
  title={{BLOOM}: A {176B}-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={CoRR},
  volume={abs/2211.05100},
  year={2022}
}

@inproceedings{xwinograd,
  author       = {Niklas Muennighoff and
                  Thomas Wang and
                  Lintang Sutawika and
                  Adam Roberts and
                  Stella Biderman and
                  Teven Le Scao and
                  M. Saiful Bari and
                  Sheng Shen and
                  Zheng Xin Yong and
                  Hailey Schoelkopf and
                  Xiangru Tang and
                  Dragomir Radev and
                  Alham Fikri Aji and
                  Khalid Almubarak and
                  Samuel Albanie and
                  Zaid Alyafeai and
                  Albert Webson and
                  Edward Raff and
                  Colin Raffel},
  title        = {Crosslingual Generalization through Multitask Finetuning},
  booktitle    = {{ACL} {(1)}},
  pages        = {15991--16111},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{opt,
  title={{OPT}: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={CoRR},
  volume={abs/2205.01068},
  year={2022}
}

@article{glm-130b,
  title={{GLM-130B}: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={CoRR},
  volume={abs/2210.02414},
  year={2022}
}

@article{glm,
  title={{GLM}: General language model pretraining with autoregressive blank infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  journal={CoRR},
  volume={abs/2103.10360},
  year={2021}
}

@inproceedings{glam,
  title={{GLaM}: Efficient scaling of language models with mixture-of-experts},
  author={Du, Nan and Huang, Yanping and Dai, Andrew M and Tong, Simon and Lepikhin, Dmitry and Xu, Yuanzhong and Krikun, Maxim and Zhou, Yanqi and Yu, Adams Wei and Firat, Orhan and others},
  booktitle={International Conference on Machine Learning},
  pages={5547--5569},
  year={2022},
  organization={PMLR}
}

@article{gshard,
  title={{GShard}: Scaling giant models with conditional computation and automatic sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  journal={CoRR},
  volume={abs/2006.16668},
  year={2020}
}

@article{switch_transformer,
  author       = {William Fedus and
                  Barret Zoph and
                  Noam Shazeer},
  title        = {Switch Transformers: Scaling to Trillion Parameter Models with Simple
                  and Efficient Sparsity},
  journal      = {J. Mach. Learn. Res.},
  volume       = {23},
  pages        = {120:1--120:39},
  year         = {2022}
}

@article{stmoe,
  title={{ST-MoE}: Designing stable and transferable sparse expert models},
  author={Zoph, Barret and Bello, Irwan and Kumar, Sameer and Du, Nan and Huang, Yanping and Dean, Jeff and Shazeer, Noam and Fedus, William},
  journal={CoRR},
   volume={abs/2202.08906},
  year={2022}
}

@article{gpt-neo,
  title={{GPT-NeoX-20B}: An open-source autoregressive language model},
  author={Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and others},
  journal={CoRR},
  volume={abs/2204.06745},
  year={2022}
}

@article{gopher,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={CoRR},
  volume={abs/2112.11446},
  year={2021}
}

@article{foundation_models,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={CoRR},
  volume={abs/2108.07258},
  year={2021}
}

@misc{mpt,
    title={{MPT-30B}: Raising the bar for open-source foundation models},
    author={{Mosaic ML}},
    url={https://www.mosaicml.com/blog/mpt-30b},
    year={2023},
}

@article{falcon,
  author       = {Ebtesam Almazrouei and
                  Hamza Alobeidli and
                  Abdulaziz Alshamsi and
                  Alessandro Cappelli and
                  Ruxandra Cojocaru and
                  M{\'{e}}rouane Debbah and
                  {\'{E}}tienne Goffinet and
                  Daniel Hesslow and
                  Julien Launay and
                  Quentin Malartic and
                  Daniele Mazzotta and
                  Badreddine Noune and
                  Baptiste Pannier and
                  Guilherme Penedo},
  title        = {The {Falcon} Series of Open Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.16867},
  year         = {2023}
}

@article{t0,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={CoRR},
  volume={abs/2110.08207},
  year={2021}
}



@article{mplug-owl,
  title={{mPLUG-Owl}: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={CoRR},
  volume={abs/2304.14178},
  year={2023}
}

@techreport{baichuan2,
    author = {Aiyuan Yang and Bin Xiao and Bingning Wang and Borong Zhang and Chao Yin and Chenxu Lv and Da Pan and Dian Wang and Dong Yan and Fan Yang and Fei Deng and Feng Wang and Feng Liu and Guangwei Ai and Guosheng Dong and Haizhou Zhao and Hang Xu and Haoze Sun and Hongda Zhang and Hui Liu and Jiaming Ji and Jian Xie and Juntao Dai and Kun Fang and Lei Su and Liang Song and Lifeng Liu and Liyun Ru and Luyao Ma and Mang Wang and Mickel Liu and MingAn Lin and Nuolan Nie and Peidong Guo and Ruiyang Sun and Tao Zhang and Tianpeng Li and Tianyu Li and Wei Cheng and Weipeng Chen and Xiangrong Zeng and Xiaochuan Wang and Xiaoxi Chen and Xin Men and Xin Yu and Xuehai Pan and Yanjun Shen and Yiding Wang and Yiyu Li and Youxin Jiang and Yuchen Gao and Yupeng Zhang and Zenan Zhou and Zhiying Wu},
    title = {Baichuan 2: Open Large-scale Language Models},
    institution = {Baichuan Inc.},
    year = {2023},
    url = {https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf}
}

@article{self_align,
  title={Principle-driven self-alignment of language models from scratch with minimal human supervision},
  author={Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
  journal={CoRR},
  volume={abs/2305.03047},
  year={2023}
}

@article{wizardlm,
  title={{WizardLM}: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={CoRR},
  volume={abs/2304.12244},
  year={2023}
}

@article{expertprompting,
  title={{ExpertPrompting}: Instructing Large Language Models to be Distinguished Experts},
  author={Xu, Benfeng and Yang, An and Lin, Junyang and Wang, Quan and Zhou, Chang and Zhang, Yongdong and Mao, Zhendong},
  journal={CoRR},
  volume={abs/2305.14688},
  year={2023}
}

@article{ultrachat,
  title={Enhancing Chat Language Models by Scaling High-quality Instructional Conversations},
  author={Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Zheng, Zhi and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
  journal={CoRR},
  volume={abs/2305.14233},
  year={2023}
}

@article{baize,
  title={{BaiZe}: An open-source chat model with parameter-efficient tuning on self-chat data},
  author={Xu, Canwen and Guo, Daya and Duan, Nan and McAuley, Julian},
  journal={CoRR},
  volume={abs/2304.01196},
  year={2023}
}

@article{phoenix,
  title={Phoenix: Democratizing {ChatGPT} across languages},
  author={Chen, Zhihong and Jiang, Feng and Chen, Junying and Wang, Tiannan and Yu, Fei and Chen, Guiming and Zhang, Hongbo and Liang, Juhao and Zhang, Chen and Zhang, Zhiyi and others},
  journal={CoRR},
  volume={abs/2304.10453},
  year={2023}
}

@misc{dolly,
    author    = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
    title     = {Free {Dolly}: Introducing the World's First Truly Open Instruction-Tuned {LLM}},
    year      = {2023},
    url       = {https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm},
    urldate   = {2023-06-30}
}

@article{orca,
  title={Orca: Progressive learning from complex explanation traces of {GPT-4}},
  author={Mukherjee, Subhabrata and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed},
  journal={CoRR},
  volume={abs/2306.02707},
  year={2023}
}

@misc{moss,
  title={{MOSS}: Training Conversational Language Models from Synthetic Data}, 
  author={Tianxiang Sun and Xiaotian Zhang and Zhengfu He and Peng Li and Qinyuan Cheng and Hang Yan and Xiangyang Liu and Yunfan Shao and Qiong Tang and Xingjian Zhao and Ke Chen and Yining Zheng and Zhejian Zhou and Ruixiao Li and Jun Zhan and Yunhua Zhou and Linyang Li and Xiaogui Yang and Lingling Wu and Zhangyue Yin and Xuanjing Huang and Xipeng Qiu},
  year={2023}
}



@article{huggingface,
  title={{HuggingFace}'s transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={CoRR},
  volume={abs/1910.03771},
  year={2019}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={CoRR},
  volume={abs/1412.6980},
  year={2014}
}

@article{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={CoRR},
  volume={abs/1711.05101},
  year={2017}
}

@inproceedings{ul2,
  title={{UL2}: Unifying language learning paradigms},
  author={Tay, Yi and Dehghani, Mostafa and Tran, Vinh Q and Garcia, Xavier and Wei, Jason and Wang, Xuezhi and Chung, Hyung Won and Bahri, Dara and Schuster, Tal and Zheng, Steven and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@misc{internlm,
    title={{InternLM}: A Multilingual Language Model with Progressively Enhanced Capabilities},
    author={{InternLM Team}},
    url = {https://github.com/InternLM/InternLM},
    year={2023}
}

@misc{baichuan7b,
    title={Baichuan-{7B}: A large-scale {7B} pretraining language model developed by {BaiChuan-Inc}},
    author={Baichuan Inc.},
    url = {https://github.com/baichuan-inc/Baichuan-7B},
    year={2023}
}

@misc{chatglm2,
    title={{ChatGLM2-6B}: An Open Bilingual Chat {LLM}},
    author={{ChatGLM2 Team}},
    url = {https://github.com/THUDM/ChatGLM2-6B},
    year={2023}
}

@misc{xverse,
    title={{XVERSE-13B}: A multilingual large language model developed by {XVERSE Technology Inc.}},
    author={XVERSE Technology Inc.},
    url = {https://github.com/xverse-ai/XVERSE-13B},
    year={2023}
}

@misc{baichuan13b,
    title={Baichuan-{13B}: A {13B} large language model developed by Baichuan Intelligent Technology},
    author={Baichuan Inc.},
    url = {https://github.com/baichuan-inc/Baichuan-13B},
    year={2023}
}

@article{upalm,
  title={Transcending scaling laws with 0.1\% extra compute},
  author={Tay, Yi and Wei, Jason and Chung, Hyung Won and Tran, Vinh Q and So, David R and Shakeri, Siamak and Garcia, Xavier and Zheng, Huaixiu Steven and Rao, Jinfeng and Chowdhery, Aakanksha and others},
  journal={CoRR},
  volume={abs/2210.11399},
  year={2022}
}

@techreport{gpt,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  institution={{OpenAI}}
}

@article{qwenvl,
  author       = {Jinze Bai and
                  Shuai Bai and
                  Shusheng Yang and
                  Shijie Wang and
                  Sinan Tan and
                  Peng Wang and
                  Junyang Lin and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {{Qwen-VL}: A Frontier Large Vision-Language Model with Versatile Abilities},
  journal      = {CoRR},
  volume       = {abs/2308.12966},
  year         = {2023}
}

@article{ofasys,
  author       = {Jinze Bai and
                  Rui Men and
                  Hao Yang and
                  Xuancheng Ren and
                  Kai Dang and
                  Yichang Zhang and
                  Xiaohuan Zhou and
                  Peng Wang and
                  Sinan Tan and
                  An Yang andf
                  Zeyu Cui and
                  Yu Han and
                  Shuai Bai and
                  Wenbin Ge and
                  Jianxin Ma and
                  Junyang Lin and
                  Jingren Zhou and
                  Chang Zhou},
  title        = {{OFASys}: {A} Multi-Modal Multi-Task Learning System for Building Generalist
                  Models},
  journal      = {CoRR},
  volume       = {abs/2212.04408},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2212.04408},
  doi          = {10.48550/arXiv.2212.04408},
  eprinttype    = {arXiv},
  eprint       = {2212.04408},
  timestamp    = {Mon, 02 Jan 2023 15:09:55 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2212-04408.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{qwen1.5_110,
    title = {{Qwen1.5-110B}: The First {100B+} Model of the {Qwen1.5} Series},
    author = {{Qwen~Team}},
    url = {https://qwenlm.github.io/blog/qwen1.5-110b/},
    year = 2024
}

@misc{rft,
      title={Scaling Relationship on Learning Mathematical Reasoning with Large Language Models}, 
      author={Zheng Yuan and Hongyi Yuan and Chengpeng Li and Guanting Dong and Keming Lu and Chuanqi Tan and Chang Zhou and Jingren Zhou},
      year={2023},
      eprint={2308.01825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{lightman2023lets,
      title={Let's Verify Step by Step}, 
      author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
      journal={CoRR},
  volume={abs/2305.20050},
      year={2023}
}

@inproceedings{math,
  author       = {Dan Hendrycks and
                  Collin Burns and
                  Saurav Kadavath and
                  Akul Arora and
                  Steven Basart and
                  Eric Tang and
                  Dawn Song and
                  Jacob Steinhardt},
  title        = {Measuring Mathematical Problem Solving With the {MATH} Dataset},
  booktitle    = {NeurIPS Datasets and Benchmarks},
  year         = {2021}
}

@article{math401,
  title={How well do Large Language Models perform in Arithmetic tasks?},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang},
  journal={CoRR},
  volume={abs/2304.02015},
  year={2023}
}

@inproceedings{Wang2017DeepNS,
  title={Deep Neural Solver for Math Word Problems},
  author={Yan Wang and Xiaojiang Liu and Shuming Shi},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:910689}
}

@article{coig,
  title={Chinese open instruction generalist: A preliminary release},
  author={Zhang, Ge and Shi, Yemin and Liu, Ruibo and Yuan, Ruibin and Li, Yizhi and Dong, Siwei and Shu, Yu and Li, Zhaoqun and Wang, Zekun and Lin, Chenghua and others},
  journal={CoRR},
  volume={abs/2304.07987},
  year={2023}
}

@misc{alpaca-cot,
  author = {Qingyi Si and Tong Wang and Naibin Gu and Rui Liu and Zheng Lin },
  insititution = {Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China},
  title = {{Alpaca-CoT}: An Instruction-Tuning Platform with Unified Interface of Instruction Collection, Parameter-efficient Methods, and Large Language Models},
  year = {2023},
  url = {https://github.com/PhoebusSi/alpaca-CoT},
}

@article{wizardmath,
  title={{WizardMath}: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  author={Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  journal={CoRR},
  volume={abs/2308.09583},
  year={2023}
}

@article{azerbayev2023proofnet,
  title={{ProofNet}: Autoformalizing and formally proving undergraduate-level mathematics},
  author={Azerbayev, Zhangir and Piotrowski, Bartosz and Schoelkopf, Hailey and Ayers, Edward W and Radev, Dragomir and Avigad, Jeremy},
  journal={CoRR},
  volume={abs/2302.12433},
  year={2023}
}

@article{liu2023goat,
  title={Goat: Fine-tuned {LLaMA} Outperforms {GPT-4} on Arithmetic Tasks},
  author={Liu, Tiedong and Low, Bryan Kian Hsiang},
  journal={CoRR},
  volume={abs/2305.14201},
  year={2023}
}

@article{AlphaCode,
  author       = {Yujia Li and
                  David H. Choi and
                  Junyoung Chung and
                  Nate Kushman and
                  Julian Schrittwieser and
                  R{\'{e}}mi Leblond and
                  Tom Eccles and
                  James Keeling and
                  Felix Gimeno and
                  Agustin Dal Lago and
                  Thomas Hubert and
                  Peter Choy and
                  Cyprien de Masson d'Autume and
                  Igor Babuschkin and
                  Xinyun Chen and
                  Po{-}Sen Huang and
                  Johannes Welbl and
                  Sven Gowal and
                  Alexey Cherepanov and
                  James Molloy and
                  Daniel J. Mankowitz and
                  Esme Sutherland Robson and
                  Pushmeet Kohli and
                  Nando de Freitas and
                  Koray Kavukcuoglu and
                  Oriol Vinyals},
  title        = {Competition-Level Code Generation with {AlphaCode}},
  journal      = {CoRR},
  volume       = {abs/2203.07814},
  year         = {2022},
}

@article{LaMDA,
  author       = {Romal Thoppilan and
                  Daniel De Freitas and
                  Jamie Hall and
                  Noam Shazeer and
                  Apoorv Kulshreshtha and
                  Heng{-}Tze Cheng and
                  Alicia Jin and
                  Taylor Bos and
                  Leslie Baker and
                  Yu Du and
                  YaGuang Li and
                  Hongrae Lee and
                  Huaixiu Steven Zheng and
                  Amin Ghafouri and
                  Marcelo Menegali and
                  Yanping Huang and
                  Maxim Krikun and
                  Dmitry Lepikhin and
                  James Qin and
                  Dehao Chen and
                  Yuanzhong Xu and
                  Zhifeng Chen and
                  Adam Roberts and
                  Maarten Bosma and
                  Yanqi Zhou and
                  Chung{-}Ching Chang and
                  Igor Krivokon and
                  Will Rusch and
                  Marc Pickett and
                  Kathleen S. Meier{-}Hellstern and
                  Meredith Ringel Morris and
                  Tulsee Doshi and
                  Renelito Delos Santos and
                  Toju Duke and
                  Johnny Soraker and
                  Ben Zevenbergen and
                  Vinodkumar Prabhakaran and
                  Mark Diaz and
                  Ben Hutchinson and
                  Kristen Olson and
                  Alejandra Molina and
                  Erin Hoffman{-}John and
                  Josh Lee and
                  Lora Aroyo and
                  Ravi Rajakumar and
                  Alena Butryna and
                  Matthew Lamm and
                  Viktoriya Kuzmina and
                  Joe Fenton and
                  Aaron Cohen and
                  Rachel Bernstein and
                  Ray Kurzweil and
                  Blaise Ag{\"{u}}era y Arcas and
                  Claire Cui and
                  Marian Croak and
                  Ed H. Chi and
                  Quoc Le},
  title        = {{LaMDA}: Language Models for Dialog Applications},
  journal      = {CoRR},
  volume       = {abs/2201.08239},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.08239},
  eprinttype    = {arXiv},
  eprint       = {2201.08239},
}

@article{livecodebench,
  author       = {Naman Jain and
                  King Han and
                  Alex Gu and
                  Wen{-}Ding Li and
                  Fanjia Yan and
                  Tianjun Zhang and
                  Sida Wang and
                  Armando Solar{-}Lezama and
                  Koushik Sen and
                  Ion Stoica},
  title        = {{LiveCodeBench}: Holistic and Contamination Free Evaluation of Large
                  Language Models for Code},
  journal      = {CoRR},
  volume       = {abs/2403.07974},
  year         = {2024}
}

@article{codex,
  author       = {Mark Chen and
                  Jerry Tworek and
                  Heewoo Jun and
                  Qiming Yuan and
                  Henrique Pond{\'{e}} de Oliveira Pinto and
                  Jared Kaplan and
                  Harrison Edwards and
                  Yuri Burda and
                  Nicholas Joseph and
                  Greg Brockman and
                  Alex Ray and
                  Raul Puri and
                  Gretchen Krueger and
                  Michael Petrov and
                  Heidy Khlaaf and
                  Girish Sastry and
                  Pamela Mishkin and
                  Brooke Chan and
                  Scott Gray and
                  Nick Ryder and
                  Mikhail Pavlov and
                  Alethea Power and
                  Lukasz Kaiser and
                  Mohammad Bavarian and
                  Clemens Winter and
                  Philippe Tillet and
                  Felipe Petroski Such and
                  Dave Cummings and
                  Matthias Plappert and
                  Fotios Chantzis and
                  Elizabeth Barnes and
                  Ariel Herbert{-}Voss and
                  William Hebgen Guss and
                  Alex Nichol and
                  Alex Paino and
                  Nikolas Tezak and
                  Jie Tang and
                  Igor Babuschkin and
                  Suchir Balaji and
                  Shantanu Jain and
                  William Saunders and
                  Christopher Hesse and
                  Andrew N. Carr and
                  Jan Leike and
                  Joshua Achiam and
                  Vedant Misra and
                  Evan Morikawa and
                  Alec Radford and
                  Matthew Knight and
                  Miles Brundage and
                  Mira Murati and
                  Katie Mayer and
                  Peter Welinder and
                  Bob McGrew and
                  Dario Amodei and
                  Sam McCandlish and
                  Ilya Sutskever and
                  Wojciech Zaremba},
  title        = {Evaluating Large Language Models Trained on Code},
  journal      = {CoRR},
  volume       = {abs/2107.03374},
  year         = {2021},
  url          = {https://arxiv.org/abs/2107.03374},
  eprinttype    = {arXiv},
  eprint       = {2107.03374},
}
@misc{Azure,
  author = {Microsoft},
  insititution = {Microsoft},
  title = {Azure openai service models},
  year = {2023},
  url = {https://learn.microsoft.com/en-us/azure/
cognitive-services/openai/concepts/models},
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford {Alpaca}: An Instruction-following {LLaMA} model},
  year = {2023},
  url = {https://github.com/tatsu-lab/stanford_alpaca},
}

@misc{codealpaca,
  author = {Sahil Chaudhary},
  title = {Code {Alpaca}: An Instruction-following {LLaMA} model for code generation},
  year = {2023},
  url = {https://github.com/sahil280114/codealpaca},
}

@article{lora,
  title={{LoRA}: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={CoRR},
  volume={abs/2106.09685},
  year={2021}
}

@article{chatdb,
  title={ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory},
  author={Hu, Chenxu and Fu, Jie and Du, Chenzhuang and Luo, Simian and Zhao, Junbo and Zhao, Hang},
  journal={CoRR},
  volume={abs/2306.03901},
  year={2023}
}

@article{memorybank,
  title={{MemoryBank}: Enhancing Large Language Models with Long-Term Memory},
  author={Zhong, Wanjun and Guo, Lianghong and Gao, Qiqi and Wang, Yanlin},
  journal={CoRR},
  volume={abs/2305.10250},
  year={2023}
}

@article{webgpt,
  title={{WebGPT}: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={CoRR},
  volume={abs/2112.09332},
  year={2021}
}

@article{webglm,
  title={{WebGLM}: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences},
  author={Liu, Xiao and Lai, Hanyu and Yu, Hao and Xu, Yifan and Zeng, Aohan and Du, Zhengxiao and Zhang, Peng and Dong, Yuxiao and Tang, Jie},
  journal={CoRR},
  volume={abs/2306.07906},
  year={2023}
}

@article{hugginggpt,
  title={{HuggingGPT}: Solving {AI} tasks with {ChatGPT} and its friends in {HuggingFace}},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={CoRR},
  volume={abs/2303.17580},
  year={2023}
}

@article{modelscope_agent,
  title={{ModelScope-Agent}: Building Your Customizable Agent System with Open-source Large Language Models},
  author={Li, Chenliang and Chen, Hehong and Yan, Ming and Shen, Weizhou and Xu, Haiyang and Wu, Zhikai and Zhang, Zhicheng and Zhou, Wenmeng and Chen, Yingda and Cheng, Chen and others},
  journal={CoRR},
  volume={abs/2309.00986},
  year={2023}
}

@article{qlora,
  title={{QLoRA}: Efficient finetuning of quantized {LLMs}},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={CoRR},
  volume={abs/2305.14314},
  year={2023}
}

@article{agentverse,
  title={AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents},
  author={Chen, Weize and Su, Yusheng and Zuo, Jingwei and Yang, Cheng and Yuan, Chenfei and Qian, Chen and Chan, Chi-Min and Qin, Yujia and Lu, Yaxi and Xie, Ruobing and others},
  journal={CoRR},
  volume={abs/2308.10848},
  year={2023}
}

@article{camel,
  title={Camel: Communicative agents for ``mind'' exploration of large scale language model society},
  author={Li, Guohao and Hammoud, Hasan Abed Al Kader and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  journal={CoRR},
  volume={abs/2303.17760},
  year={2023}
}

@article{voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={CoRR},
  volume={abs/2305.16291},
  year={2023}
}

@article{metagpt,
  title={Metagpt: Meta programming for multi-agent collaborative framework},
  author={Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and Ran, Chenyu and others},
  journal={CoRR},
  volume={abs/2308.00352},
  year={2023}
}

@article{santacoder,
  title={{SantaCoder}: Don't reach for the stars!},
  author={Allal, Loubna Ben and Li, Raymond and Kocetkov, Denis and Mou, Chenghao and Akiki, Christopher and Ferrandis, Carlos Munoz and Muennighoff, Niklas and Mishra, Mayank and Gu, Alex and Dey, Manan and others},
  journal={CoRR},
  volume={abs/2301.03988},
  year={2023}
}

@article{palm-e,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={CoRR},
  volume={abs/2303.03378},
  year={2023}
}

@article{incoder,
  title={InCoder: A Generative Model for Code Infilling and Synthesis},
  author={Daniel Fried and Armen Aghajanyan and Jessy Lin and Sida I. Wang and Eric Wallace and Freda Shi and Ruiqi Zhong and Wen-tau Yih and Luke Zettlemoyer and Mike Lewis},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.05999}
}

@article{scratchpad,
  title={Show Your Work: Scratchpads for Intermediate Computation with Language Models},
  author={Maxwell Nye and Anders Andreassen and Guy Gur-Ari and Henryk Michalewski and Jacob Austin and David Bieber and David Dohan and Aitor Lewkowycz and Maarten Bosma and David Luan and Charles Sutton and Augustus Odena},
  journal={ArXiv},
  year={2021},
  volume={abs/2112.00114}
}

@article{self_consistency,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Huai-hsin Chi and Denny Zhou},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.11171}
}

@article{least_to_most,
  title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
  author={Denny Zhou and Nathanael Scharli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Olivier Bousquet and Quoc Le and Ed Huai-hsin Chi},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.10625}
}

@article{codet5,
  title={{CodeT5}: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven CH},
  journal={CoRR},
  volume={abs/2109.00859},
  year={2021}
}

@article{werewolf,
  title={Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf},
  author={Xu, Yuzhuang and Wang, Shuo and Li, Peng and Luo, Fuwen and Wang, Xiaolong and Liu, Weidong and Liu, Yang},
  journal={CoRR},
  volume={abs/2309.04658},
  year={2023}
}

@article{bnb,
  title={{LLM.int8()}: 8-bit Matrix Multiplication for Transformers at Scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal={CoRR},
  volume={abs/2208.07339},
  year={2022}
}

@article{belle,
  title={Exploring the impact of instruction data scaling on large language models: An empirical study on real-world use cases},
  author={Ji, Yunjie and Deng, Yong and Gong, Yan and Peng, Yiping and Niu, Qiang and Zhang, Lei and Ma, Baochang and Li, Xiangang},
  journal={CoRR},
  volume={abs/2303.14742},
  year={2023}
}

@misc{vicuna,
    title = {Vicuna: An Open-Source Chatbot Impressing {GPT-4} with 90\%* {ChatGPT} Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{tulu,
  title={How Far Can Camels Go? {Exploring} the State of Instruction Tuning on Open Resources},
  author={Wang, Yizhong and Ivison, Hamish and Dasigi, Pradeep and Hessel, Jack and Khot, Tushar and Chandu, Khyathi Raghavi and Wadden, David and MacMillan, Kelsey and Smith, Noah A and Beltagy, Iz and others},
  journal={CoRR},
  volume={abs/2306.04751},
  year={2023}
}

@misc{firefly,
  author = {Jianxin Yang},
  title = {Firefly},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/yangjianxin1/Firefly}},
}

@article{gptq,
  title={{GPTQ}: Accurate post-training quantization for generative pre-trained transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={CoRR},
  volume={abs/2210.17323},
  year={2022}
}

@inproceedings{pageattention,
  title={Efficient Memory Management for Large Language Model Serving with {PagedAttention}}, 
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@article{rrhf,
  title={Rrhf: Rank responses to align language models with human feedback without tears},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang and Huang, Fei},
  journal={CoRR},
  volume={abs/2304.05302},
  year={2023}
}

@article{pro,
  title={Preference ranking optimization for human alignment},
  author={Song, Feifan and Yu, Bowen and Li, Minghao and Yu, Haiyang and Huang, Fei and Li, Yongbin and Wang, Houfeng},
  journal={CoRR},
  volume={abs/2306.17492},
  year={2023}
}

@misc{leetcode-solutions,
  author = {Eric Hartford},
title = {leetcode-solutions},
year = {2023},
url = {https://www.kaggle.com/datasets/erichartford/leetcode-solutions}
}

@misc{autogpt,
  author = {AutoGPT},
title = {{AutoGPT}: The heart of the open-source agent ecosystem},
year = {2023},
url = {https://github.com/Significant-Gravitas/Auto-GPT}
}

@misc{leetcode-solutions-python,
  author = {Le Vu Minh Huy},
title = {leetcode-solutions-python},
year = {2023},
url = {https://huggingface.co/datasets/mhhmm/leetcode-solutions-python}
}

@misc{evol,
author = {Nick Roshdieh},
title = {evol-teacher: Open Source {WizardCoder} Dataset},
year = {2023},
url = {https://github.com/nickrosh/evol-teacher}
}

@misc{codefuse-evol-instrution-66k,
author = {{CodeFuse}},
title = {{CodeFuse} Evol-Instruction-66k},
year = {2023},
url = {https://huggingface.co/datasets/codefuse-ai/Evol-instruction-66k}
}

@misc{codefuse-code-exercise-python-27k,
author = {{CodeFuse}},
title = {{CodeFuse} CodeExercise-Python-27k},
year = {2023},
url = {https://huggingface.co/datasets/codefuse-ai/CodeExercise-Python-27k}
}

@misc{TAL-SCQ5K-CN,
author={{MathGPT}},
title = {TAL-SCQ5K-CN Dataset},
year={2023},
url={https://www.mathgpt.com}
}

@inproceedings{codegen,
  author       = {Erik Nijkamp and
                  Bo Pang and
                  Hiroaki Hayashi and
                  Lifu Tu and
                  Huan Wang and
                  Yingbo Zhou and
                  Silvio Savarese and
                  Caiming Xiong},
  title        = {{CodeGen}: An Open Large Language Model for Code with Multi-Turn Program
                  Synthesis},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
}
@article{CodeGeeX,
  author       = {Qinkai Zheng and
                  Xiao Xia and
                  Xu Zou and
                  Yuxiao Dong and
                  Shan Wang and
                  Yufei Xue and
                  Zihan Wang and
                  Lei Shen and
                  Andi Wang and
                  Yang Li and
                  Teng Su and
                  Zhilin Yang and
                  Jie Tang},
  title        = {{CodeGeeX}: {A} Pre-Trained Model for Code Generation with Multilingual
                  Evaluations on HumanEval-X},
  journal      = {CoRR},
  volume       = {abs/2303.17568},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.17568},
  doi          = {10.48550/arXiv.2303.17568},
  eprinttype    = {arXiv},
  eprint       = {2303.17568},
}

@article{CodeT5+,
  author       = {Yue Wang and
                  Hung Le and
                  Akhilesh Deepak Gotmare and
                  Nghi D. Q. Bui and
                  Junnan Li and
                  Steven C. H. Hoi},
  title        = {{CodeT5+}: Open Code Large Language Models for Code Understanding and
                  Generation},
  journal      = {CoRR},
  volume       = {abs/2305.07922},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.07922},
  doi          = {10.48550/arXiv.2305.07922},
  eprinttype    = {arXiv},
  eprint       = {2305.07922},
}

@inproceedings{self_instruct,
  author       = {Yizhong Wang and
                  Yeganeh Kordi and
                  Swaroop Mishra and
                  Alisa Liu and
                  Noah A. Smith and
                  Daniel Khashabi and
                  Hannaneh Hajishirzi},
  editor       = {Anna Rogers and
                  Jordan L. Boyd{-}Graber and
                  Naoaki Okazaki},
  title        = {{Self-Instruct}: Aligning Language Models with Self-Generated Instructions},
  booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto, Canada,
                  July 9-14, 2023},
  pages        = {13484--13508},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.acl-long.754},
  doi          = {10.18653/v1/2023.acl-long.754},
  timestamp    = {Thu, 10 Aug 2023 12:35:44 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/WangKMLSKH23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{Wei2022EmergentAO,
  title={Emergent Abilities of Large Language Models},
  author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed Huai-hsin Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  journal={Trans. Mach. Learn. Res.},
  year={2022},
  volume={2022},
  url={https://api.semanticscholar.org/CorpusID:249674500}
}
@article{octopack,
  author       = {Niklas Muennighoff and
                  Qian Liu and
                  Armel Zebaze and
                  Qinkai Zheng and
                  Binyuan Hui and
                  Terry Yue Zhuo and
                  Swayam Singh and
                  Xiangru Tang and
                  Leandro von Werra and
                  Shayne Longpre},
  title        = {{OctoPack}: Instruction Tuning Code Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2308.07124},
  year         = {2023},
}

@misc{yuan2023rrhf,
      title={{RRHF}: Rank Responses to Align Language Models with Human Feedback without tears}, 
      author={Zheng Yuan and Hongyi Yuan and Chuanqi Tan and Wei Wang and Songfang Huang and Fei Huang},
      year={2023},
      eprint={2304.05302},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ntk,
      title={{NTK}-Aware Scaled {RoPE} allows {LLaMA} models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation.}, 
      author={bloc97},
      year={2023},
      url={https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/}
}

@inproceedings{logn_attn,
  title={Overcoming a Theoretical Limitation of Self-Attention},
  author={Chiang, David and Cholak, Peter},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7654--7664},
  year={2022}
}

@article{window_attn,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={CoRR},
  volume={abs/2004.05150},
  year={2020}
}

@misc{qkv_bias,
  title={The magical effect of the {Bias} term: {RoPE} + {Bias} = better length extrapolation},
  author={Jianlin Su},
  year={2023},
  url={https://spaces.ac.cn/archives/9577}
}




@article{wizardcoder,
  title={{WizardCoder}: Empowering Code Large Language Models with Evol-Instruct},
  author={Luo, Ziyang and Xu, Can and Zhao, Pu and Sun, Qingfeng and Geng, Xiubo and Hu, Wenxiang and Tao, Chongyang and Ma, Jing and Lin, Qingwei and Jiang, Daxin},
  journal={CoRR},
  volume={abs/2306.08568},
  year={2023}
}


@article{PMP,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={CoRR},
  volume={abs/2204.05862},
  year={2022}
}

@article{askell2021general,
  title={A general language assistant as a laboratory for alignment},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={CoRR},
  volume={abs/2112.00861},
  year={2021}
}

@article{bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={CoRR},
  volume={abs/1810.04805},
  year={2018}
}

@article{ppo,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={CoRR},
  volume={abs/1707.06347},
  year={2017}
}

@article{learn-summary,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}



@article{yarn,
  author       = {Bowen Peng and
                  Jeffrey Quesnelle and
                  Honglu Fan and
                  Enrico Shippole},
  title        = {{YaRN}: Efficient Context Window Extension of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.00071},
  year         = {2023}
}

@inproceedings{upcycle,
  author       = {Aran Komatsuzaki and
                  Joan Puigcerver and
                  James Lee{-}Thorp and
                  Carlos Riquelme Ruiz and
                  Basil Mustafa and
                  Joshua Ainslie and
                  Yi Tay and
                  Mostafa Dehghani and
                  Neil Houlsby},
  title        = {Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@article{deepseekmoe,
  author       = {Damai Dai and
                  Chengqi Deng and
                  Chenggang Zhao and
                  R. X. Xu and
                  Huazuo Gao and
                  Deli Chen and
                  Jiashi Li and
                  Wangding Zeng and
                  Xingkai Yu and
                  Y. Wu and
                  Zhenda Xie and
                  Y. K. Li and
                  Panpan Huang and
                  Fuli Luo and
                  Chong Ruan and
                  Zhifang Sui and
                  Wenfeng Liang},
  title        = {{DeepSeekMoE}: Towards Ultimate Expert Specialization in Mixture-of-Experts
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2401.06066},
  year         = {2024}
}

@inproceedings{deepspeedmoe,
  author       = {Samyam Rajbhandari and
                  Conglong Li and
                  Zhewei Yao and
                  Minjia Zhang and
                  Reza Yazdani Aminabadi and
                  Ammar Ahmad Awan and
                  Jeff Rasley and
                  Yuxiong He},
  title        = {{DeepSpeed-MoE}: Advancing Mixture-of-Experts Inference and Training
                  to Power Next-Generation {AI} Scale},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {162},
  pages        = {18332--18346},
  publisher    = {{PMLR}},
  year         = {2022}
}

@article{qwen,
author       = {Jinze Bai and
                  Shuai Bai and
                  Yunfei Chu and
                  Zeyu Cui and
                  Kai Dang and
                  Xiaodong Deng and
                  Yang Fan and
                  Wenbin Ge and
                  Yu Han and
                  Fei Huang and
                  Binyuan Hui and
                  Luo Ji and
                  Mei Li and
                  Junyang Lin and
                  Runji Lin and
                  Dayiheng Liu and
                  Gao Liu and
                  Chengqiang Lu and
                  Keming Lu and
                  Jianxin Ma and
                  Rui Men and
                  Xingzhang Ren and
                  Xuancheng Ren and
                  Chuanqi Tan and
                  Sinan Tan and
                  Jianhong Tu and
                  Peng Wang and
                  Shijie Wang and
                  Wei Wang and
                  Shengguang Wu and
                  Benfeng Xu and
                  Jin Xu and
                  An Yang and
                  Hao Yang and
                  Jian Yang and
                  Shusheng Yang and
                  Yang Yao and
                  Bowen Yu and
                  Hongyi Yuan and
                  Zheng Yuan and
                  Jianwei Zhang and
                  Xingxuan Zhang and
                  Yichang Zhang and
                  Zhenru Zhang and
                  Chang Zhou and
                  Jingren Zhou and
                  Xiaohuan Zhou and
                  Tianhang Zhu},
  title        = {Qwen Technical Report},
  journal      = {CoRR},
  volume       = {abs/2309.16609},
  year         = {2023}
}

@inproceedings{gqa,
  author       = {Joshua Ainslie and
                  James Lee{-}Thorp and
                  Michiel de Jong and
                  Yury Zemlyanskiy and
                  Federico Lebr{\'{o}}n and
                  Sumit Sanghai},
  title        = {{GQA}: Training Generalized Multi-Query {Transformer} Models from Multi-Head
                  Checkpoints},
  booktitle    = {{EMNLP}},
  pages        = {4895--4901},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{cot,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@misc{taylor2022galactica,
      title={Galactica: A Large Language Model for Science}, 
      author={Ross Taylor and Marcin Kardas and Guillem Cucurull and Thomas Scialom and Anthony Hartshorn and Elvis Saravia and Andrew Poulton and Viktor Kerkez and Robert Stojnic},
      year={2022},
      eprint={2211.09085},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lewkowycz2022solving,
      title={Solving Quantitative Reasoning Problems with Language Models}, 
      author={Aitor Lewkowycz and Anders Andreassen and David Dohan and Ethan Dyer and Henryk Michalewski and Vinay Ramasesh and Ambrose Slone and Cem Anil and Imanol Schlag and Theo Gutman-Solo and Yuhuai Wu and Behnam Neyshabur and Guy Gur-Ari and Vedant Misra},
      year={2022},
      eprint={2206.14858},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{yue2023mammoth,
  title={{MAmmoTH}: Building Math Generalist Models through Hybrid Instruction Tuning},
  author={Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu},
  journal={CoRR},
  volume={abs/2309.05653},
  year={2023}
}


@inproceedings{code_translation_compiler,
  author       = {Marc Szafraniec and
                  Baptiste Rozi{\`{e}}re and
                  Hugh Leather and
                  Patrick Labatut and
                  Fran{\c{c}}ois Charton and
                  Gabriel Synnaeve},
  title        = {Code Translation with Compiler Representations},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/pdf?id=XomEU3eNeSQ},
  timestamp    = {Fri, 30 Jun 2023 14:55:53 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/SzafraniecRLLCS23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{repocoder,
  author       = {Fengji Zhang and
                  Bei Chen and
                  Yue Zhang and
                  Jin Liu and
                  Daoguang Zan and
                  Yi Mao and
                  Jian{-}Guang Lou and
                  Weizhu Chen},
  title        = {{RepoCoder}: Repository-Level Code Completion Through Iterative Retrieval
                  and Generation},
  journal      = {CoRR},
  volume       = {abs/2303.12570},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.12570},
  doi          = {10.48550/arXiv.2303.12570},
  eprinttype    = {arXiv},
  eprint       = {2303.12570},
  timestamp    = {Thu, 13 Apr 2023 17:40:16 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-12570.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{code_refinement,
  author       = {Yue Liu and
                  Thanh Le{-}Cong and
                  Ratnadira Widyasari and
                  Chakkrit Tantithamthavorn and
                  Li Li and
                  Xuan{-}Bach Dinh Le and
                  David Lo},
  title        = {Refining {ChatGPT}-Generated Code: Characterizing and Mitigating Code
                  Quality Issues},
  journal      = {CoRR},
  volume       = {abs/2307.12596},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.12596},
  doi          = {10.48550/arXiv.2307.12596},
  eprinttype    = {arXiv},
  eprint       = {2307.12596},
  timestamp    = {Tue, 01 Aug 2023 14:49:51 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2307-12596.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{code_qa,
  author       = {Chenxiao Liu and
                  Xiaojun Wan},
  editor       = {Marie{-}Francine Moens and
                  Xuanjing Huang and
                  Lucia Specia and
                  Scott Wen{-}tau Yih},
  title        = {{CodeQA}: {A} Question Answering Dataset for Source Code Comprehension},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November,
                  2021},
  pages        = {2618--2632},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
  url          = {https://doi.org/10.18653/v1/2021.findings-emnlp.223},
  doi          = {10.18653/v1/2021.findings-emnlp.223},
  timestamp    = {Thu, 20 Jan 2022 10:02:06 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/Liu021.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{logn_su,
  title={Improving Transformer: Length Extrapolation Ability and Position Robustness},
  author={Jianlin Su},
  year={2023},
  url={https://spaces.ac.cn/archives/9444}
}


@article{code_search_net,
  author       = {Hamel Husain and
                  Ho{-}Hsiang Wu and
                  Tiferet Gazit and
                  Miltiadis Allamanis and
                  Marc Brockschmidt},
  title        = {CodeSearchNet Challenge: Evaluating the State of Semantic Code Search},
  journal      = {CoRR},
  volume       = {abs/1909.09436},
  year         = {2019},
  url          = {http://arxiv.org/abs/1909.09436},
  eprinttype    = {arXiv},
  eprint       = {1909.09436},
  timestamp    = {Tue, 24 Sep 2019 11:33:51 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1909-09436.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{agieval,
  author       = {Wanjun Zhong and
                  Ruixiang Cui and
                  Yiduo Guo and
                  Yaobo Liang and
                  Shuai Lu and
                  Yanlin Wang and
                  Amin Saied and
                  Weizhu Chen and
                  Nan Duan},
  title        = {{AGIEval}: {A} Human-Centric Benchmark for Evaluating Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2304.06364},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.06364},
  doi          = {10.48550/arXiv.2304.06364},
  eprinttype    = {arXiv},
  eprint       = {2304.06364},
  timestamp    = {Wed, 19 Apr 2023 12:42:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2304-06364.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}




@article{gaokao-bench,
  author       = {Xiaotian Zhang and
                  Chunyang Li and
                  Yi Zong and
                  Zhengyu Ying and
                  Liang He and
                  Xipeng Qiu},
  title        = {Evaluating the Performance of Large Language Models on {GAOKAO} Benchmark},
  journal      = {CoRR},
  volume       = {abs/2305.12474},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.12474},
  doi          = {10.48550/arXiv.2305.12474},
  eprinttype    = {arXiv},
  eprint       = {2305.12474},
  timestamp    = {Fri, 26 May 2023 11:29:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-12474.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{arc,
  author       = {Peter Clark and
                  Isaac Cowhey and
                  Oren Etzioni and
                  Tushar Khot and
                  Ashish Sabharwal and
                  Carissa Schoenick and
                  Oyvind Tafjord},
  title        = {Think you have Solved Question Answering? {Try} {ARC}, the {AI2} Reasoning
                  Challenge},
  journal      = {CoRR},
  volume       = {abs/1803.05457},
  year         = {2018}
}



@inproceedings{boolq,
  author       = {Christopher Clark and
                  Kenton Lee and
                  Ming{-}Wei Chang and
                  Tom Kwiatkowski and
                  Michael Collins and
                  Kristina Toutanova},
  editor       = {Jill Burstein and
                  Christy Doran and
                  Thamar Solorio},
  title        = {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
                  and Short Papers)},
  pages        = {2924--2936},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/n19-1300},
  doi          = {10.18653/v1/n19-1300},
  timestamp    = {Tue, 16 Aug 2022 23:04:27 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/ClarkLCK0T19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{commonsenseqa,
  author       = {Alon Talmor and
                  Jonathan Herzig and
                  Nicholas Lourie and
                  Jonathan Berant},
  editor       = {Jill Burstein and
                  Christy Doran and
                  Thamar Solorio},
  title        = {{CommonsenseQA}: {A} Question Answering Challenge Targeting Commonsense
                  Knowledge},
  booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
                  and Short Papers)},
  pages        = {4149--4158},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/n19-1421},
  doi          = {10.18653/v1/n19-1421},
  timestamp    = {Fri, 06 Aug 2021 00:41:31 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/TalmorHLB19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}




@article{naturalquestions,
  author       = {Tom Kwiatkowski and
                  Jennimaria Palomaki and
                  Olivia Redfield and
                  Michael Collins and
                  Ankur P. Parikh and
                  Chris Alberti and
                  Danielle Epstein and
                  Illia Polosukhin and
                  Jacob Devlin and
                  Kenton Lee and
                  Kristina Toutanova and
                  Llion Jones and
                  Matthew Kelcey and
                  Ming{-}Wei Chang and
                  Andrew M. Dai and
                  Jakob Uszkoreit and
                  Quoc Le and
                  Slav Petrov},
  title        = {Natural Questions: a Benchmark for Question Answering Research},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {7},
  pages        = {452--466},
  year         = {2019},
  url          = {https://doi.org/10.1162/tacl\_a\_00276},
  doi          = {10.1162/tacl\_a\_00276},
  timestamp    = {Tue, 16 Aug 2022 23:05:11 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/KwiatkowskiPRCP19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{pmlr-v162-ethayarajh22a,
  title = 	 {Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information},
  author =       {Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {5988--6008},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher = {PMLR},
}



@inproceedings{lambada,
  author       = {Denis Paperno and
                  Germ{\'{a}}n Kruszewski and
                  Angeliki Lazaridou and
                  Quan Ngoc Pham and
                  Raffaella Bernardi and
                  Sandro Pezzelle and
                  Marco Baroni and
                  Gemma Boleda and
                  Raquel Fern{\'{a}}ndez},
  title        = {The {LAMBADA} dataset: Word prediction requiring a broad discourse
                  context},
  booktitle    = {Proceedings of the 54th Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2016, August 7-12, 2016, Berlin, Germany, Volume
                  1: Long Papers},
  publisher    = {The Association for Computer Linguistics},
  year         = {2016},
  url          = {https://doi.org/10.18653/v1/p16-1144},
  doi          = {10.18653/v1/p16-1144},
  timestamp    = {Fri, 06 Aug 2021 00:41:02 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/PapernoKLPBPBBF16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{ocnli,
  author       = {Hai Hu and
                  Kyle Richardson and
                  Liang Xu and
                  Lu Li and
                  Sandra K{\"{u}}bler and
                  Lawrence S. Moss},
  editor       = {Trevor Cohn and
                  Yulan He and
                  Yang Liu},
  title        = {{OCNLI:} Original Chinese Natural Language Inference},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2020, Online Event, 16-20 November 2020},
  series       = {Findings of {ACL}},
  volume       = {{EMNLP} 2020},
  pages        = {3512--3526},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
  url          = {https://doi.org/10.18653/v1/2020.findings-emnlp.314},
  doi          = {10.18653/v1/2020.findings-emnlp.314},
  timestamp    = {Wed, 23 Mar 2022 10:11:55 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/HuRXLKM20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{hellaswag,
  author       = {Rowan Zellers and
                  Ari Holtzman and
                  Yonatan Bisk and
                  Ali Farhadi and
                  Yejin Choi},
  title        = {{HellaSwag}: Can a Machine Really Finish Your Sentence?},
  booktitle    = {{ACL} {(1)}},
  pages        = {4791--4800},
  publisher    = {Association for Computational Linguistics},
  year         = {2019}
}



@inproceedings{piqa,
  author       = {Yonatan Bisk and
                  Rowan Zellers and
                  Ronan Le Bras and
                  Jianfeng Gao and
                  Yejin Choi},
  title        = {{PIQA:} Reasoning about Physical Commonsense in Natural Language},
  booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                  February 7-12, 2020},
  pages        = {7432--7439},
  publisher    = {{AAAI} Press},
  year         = {2020},
  url          = {https://doi.org/10.1609/aaai.v34i05.6239},
  doi          = {10.1609/aaai.v34i05.6239},
  timestamp    = {Mon, 04 Sep 2023 16:50:23 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/BiskZLGC20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{arena-hard,
      title={From Crowdsourced Data to High-Quality Benchmarks: {Arena-Hard} and {BenchBuilder} Pipeline}, 
      author={Tianle Li and Wei-Lin Chiang and Evan Frick and Lisa Dunlap and Tianhao Wu and Banghua Zhu and Joseph E. Gonzalez and Ion Stoica},
      year={2024},
      journal={CoRR},
      volume={abs/2406.11939}
}

@article{mixeval,
  title={{MixEval}: Deriving Wisdom of the Crowd from {LLM} Benchmark Mixtures},
  author={Ni, Jinjie and Xue, Fuzhao and Yue, Xiang and Deng, Yuntian and Shah, Mahir and Jain, Kabir and Neubig, Graham and You, Yang},
  journal={CoRR}, 
  volume={abs/2406.06565},
  year={2024}
}

@article{alignbench,
  author       = {Xiao Liu and
                  Xuanyu Lei and
                  Shengyuan Wang and
                  Yue Huang and
                  Zhuoer Feng and
                  Bosi Wen and
                  Jiale Cheng and
                  Pei Ke and
                  Yifan Xu and
                  Weng Lam Tam and
                  Xiaohan Zhang and
                  Lichao Sun and
                  Hongning Wang and
                  Jing Zhang and
                  Minlie Huang and
                  Yuxiao Dong and
                  Jie Tang},
  title        = {{AlignBench}: Benchmarking {Chinese} Alignment of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.18743},
  year         = {2023}
}


@article{siqa,
  author       = {Maarten Sap and
                  Hannah Rashkin and
                  Derek Chen and
                  Ronan Le Bras and
                  Yejin Choi},
  title        = {{SocialIQA}: Commonsense Reasoning about Social Interactions},
  journal      = {CoRR},
  volume       = {abs/1904.09728},
  year         = {2019},
  url          = {http://arxiv.org/abs/1904.09728},
  eprinttype    = {arXiv},
  eprint       = {1904.09728},
  timestamp    = {Sat, 29 Apr 2023 10:09:27 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1904-09728.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@misc{abel,
  author = {Chern, Ethan and Zou, Haoyang and Li, Xuefeng and Hu, Jiewen and Feng, Kehua and Li, Junlong and Liu, Pengfei},
  title = {Generative AI for Math: Abel},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/GAIR-NLP/abel}},
}

@misc{yu2023metamath,
      title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models}, 
      author={Longhui Yu and Weisen Jiang and Han Shi and Jincheng Yu and Zhengying Liu and Yu Zhang and James T. Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
      year={2023},
      eprint={2309.12284},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{chern2023factool,
  title={FacTool: Factuality Detection in Generative AI--A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios},
  author={Chern, I and Chern, Steffi and Chen, Shiqi and Yuan, Weizhe and Feng, Kehua and Zhou, Chunting and He, Junxian and Neubig, Graham and Liu, Pengfei and others},
  journal={CoRR},
  volume={abs/2307.13528},
  year={2023}
}

@article{position_interpolation,
  title={Extending context window of large language models via positional interpolation},
  author={Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong},
  journal={CoRR},
  volume={abs/2306.15595},
  year={2023}
}

@inproceedings{evalplus,
  author       = {Jiawei Liu and
                  Chunqiu Steven Xia and
                  Yuyao Wang and
                  Lingming Zhang},
  title        = {Is Your Code Generated by {ChatGPT} Really Correct? {Rigorous} Evaluation
                  of Large Language Models for Code Generation},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{chunkllama,
  author       = {Chenxin An and
                  Fei Huang and
                  Jun Zhang and
                  Shansan Gong and
                  Xipeng Qiu and
                  Chang Zhou and
                  Lingpeng Kong},
  title        = {Training-Free Long-Context Scaling of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2402.17463},
  year         = {2024}
}


@article{ropeabf,
  author       = {Wenhan Xiong and
                  Jingyu Liu and
                  Igor Molybog and
                  Hejia Zhang and
                  Prajjwal Bhargava and
                  Rui Hou and
                  Louis Martin and
                  Rashi Rungta and
                  Karthik Abinav Sankararaman and
                  Barlas Oguz and
                  Madian Khabsa and
                  Han Fang and
                  Yashar Mehdad and
                  Sharan Narang and
                  Kshitiz Malik and
                  Angela Fan and
                  Shruti Bhosale and
                  Sergey Edunov and
                  Mike Lewis and
                  Sinong Wang and
                  Hao Ma},
  title        = {Effective Long-Context Scaling of Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2309.16039},
  year         = {2023}
}

@inproceedings{koto-etal-2023-indommlu,
  author       = {Fajri Koto and
                  Nurul Aisyah and
                  Haonan Li and
                  Timothy Baldwin},
  title        = {Large Language Models Only Pass Primary School Exams in {Indonesia}:
                  {A} Comprehensive Test on {IndoMMLU}},
  booktitle    = {{EMNLP}},
  pages        = {12359--12374},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{revaut2024how,
  author       = {Mathieu Ravaut and
                  Bosheng Ding and
                  Fangkai Jiao and
                  Hailin Chen and
                  Xingxuan Li and
                  Ruochen Zhao and
                  Chengwei Qin and
                  Caiming Xiong and
                  Shafiq Joty},
  title        = {How Much are {LLMs} Contaminated? {A} Comprehensive Survey and the LLMSanitize
                  Library},
  journal      = {CoRR},
  volume       = {abs/2404.00699},
  year         = {2024}
}

@inproceedings{sainz2023nlp,
  author       = {Oscar Sainz and
                  Jon Ander Campos and
                  Iker Garc{\'{\i}}a{-}Ferrero and
                  Julen Etxaniz and
                  Oier Lopez de Lacalle and
                  Eneko Agirre},
  title        = {{NLP} Evaluation in trouble: On the Need to Measure {LLM} Data Contamination
                  for each Benchmark},
  booktitle    = {{EMNLP} (Findings)},
  pages        = {10776--10787},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@inproceedings{golchin2024time,
  author       = {Shahriar Golchin and
                  Mihai Surdeanu},
  title        = {Time Travel in LLMs: Tracing Data Contamination in Large Language
                  Models},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024}
}

@article{rummlu-mera,
  author       = {Alena Fenogenova and
                  Artem Chervyakov and
                  Nikita Martynov and
                  Anastasia Kozlova and
                  Maria Tikhonova and
                  Albina Akhmetgareeva and
                  Anton A. Emelyanov and
                  Denis Shevelev and
                  Pavel Lebedev and
                  Leonid Sinev and
                  Ulyana Isaeva and
                  Katerina Kolomeytseva and
                  Daniil Moskovskiy and
                  Elizaveta Goncharova and
                  Nikita Savushkin and
                  Polina Mikhailova and
                  Denis Dimitrov and
                  Alexander Panchenko and
                  Sergey Markov},
  title        = {{MERA:} {A} Comprehensive {LLM} Evaluation in Russian},
  journal      = {CoRR},
  volume       = {abs/2401.04531},
  year         = {2024}
}

@article{belebele,
  author       = {Lucas Bandarkar and
                  Davis Liang and
                  Benjamin Muller and
                  Mikel Artetxe and
                  Satya Narayan Shukla and
                  Donald Husa and
                  Naman Goyal and
                  Abhinandan Krishnan and
                  Luke Zettlemoyer and
                  Madian Khabsa},
  title        = {The {Belebele} Benchmark: A Parallel Reading Comprehension Dataset in
                  122 Language Variants},
  journal      = {CoRR},
  volume       = {abs/2308.16884},
  year         = {2023}
}

@inproceedings{xcopa,
  author       = {Edoardo Maria Ponti and
                  Goran Glavas and
                  Olga Majewska and
                  Qianchu Liu and
                  Ivan Vulic and
                  Anna Korhonen},
  title        = {{XCOPA}: {A} Multilingual Dataset for Causal Commonsense Reasoning},
  booktitle    = {{EMNLP} {(1)}},
  pages        = {2362--2376},
  publisher    = {Association for Computational Linguistics},
  year         = {2020}
}

@inproceedings{xstory_cloze,
      author       = {Xi Victoria Lin and
                  Todor Mihaylov and
                  Mikel Artetxe and
                  Tianlu Wang and
                  Shuohui Chen and
                  Daniel Simig and
                  Myle Ott and
                  Naman Goyal and
                  Shruti Bhosale and
                  Jingfei Du and
                  Ramakanth Pasunuru and
                  Sam Shleifer and
                  Punit Singh Koura and
                  Vishrav Chaudhary and
                  Brian O'Horo and
                  Jeff Wang and
                  Luke Zettlemoyer and
                  Zornitsa Kozareva and
                  Mona T. Diab and
                  Veselin Stoyanov and
                  Xian Li},
  title        = {Few-shot Learning with Multilingual Generative Language Models},
  booktitle    = {{EMNLP}},
  pages        = {9019--9052},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@inproceedings{paws-x,
      author       = {Yinfei Yang and
                  Yuan Zhang and
                  Chris Tar and
                  Jason Baldridge},
  title        = {{PAWS-X:} {A} Cross-lingual Adversarial Dataset for Paraphrase Identification},
  booktitle    = {{EMNLP/IJCNLP} {(1)}},
  pages        = {3685--3690},
  publisher    = {Association for Computational Linguistics},
  year         = {2019}
}

@misc{msift,
author = {Chen, Zhihong and Yan, Shuo and Liang, Juhao and Jiang, Feng and Wu, Xiangbo and Yu, Fei and Chen, Guiming Hardy and Chen, Junying and Zhang, Hongbo and Li Jianquan and Wan Xiang and Wang, Benyou},
title = {{MultilingualSIFT}: Multilingual Supervised Instruction Fine-tuning},
url = {https://github.com/FreedomIntelligence/MultilingualSIFT},
year = {2023}
}

@inproceedings{mgsm,
  author       = {Freda Shi and
                  Mirac Suzgun and
                  Markus Freitag and
                  Xuezhi Wang and
                  Suraj Srivats and
                  Soroush Vosoughi and
                  Hyung Won Chung and
                  Yi Tay and
                  Sebastian Ruder and
                  Denny Zhou and
                  Dipanjan Das and
                  Jason Wei},
  title        = {Language models are multilingual chain-of-thought reasoners},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023}
}


@article{flores,
  author       = {Naman Goyal and
                  Cynthia Gao and
                  Vishrav Chaudhary and
                  Peng{-}Jen Chen and
                  Guillaume Wenzek and
                  Da Ju and
                  Sanjana Krishnan and
                  Marc'Aurelio Ranzato and
                  Francisco Guzm{\'{a}}n and
                  Angela Fan},
  title        = {The {Flores-101} Evaluation Benchmark for Low-Resource and Multilingual
                  Machine Translation},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {10},
  pages        = {522--538},
  year         = {2022}
}

@techreport{claude3,
  title={The {Claude} 3 model family: {Opus}, {Sonnet}, {Haiku}},
  author={Anthropic},
  institution={{Anthropic, AI}},
  url={https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model\_Card\_Claude\_3.pdf},
  year={2024}
}

@article{arena,
  author       = {Wei{-}Lin Chiang and
                  Lianmin Zheng and
                  Ying Sheng and
                  Anastasios Nikolas Angelopoulos and
                  Tianle Li and
                  Dacheng Li and
                  Hao Zhang and
                  Banghua Zhu and
                  Michael I. Jordan and
                  Joseph E. Gonzalez and
                  Ion Stoica},
  title        = {Chatbot Arena: An Open Platform for Evaluating {LLMs} by Human Preference},
  journal      = {CoRR},
  volume       = {abs/2403.04132},
  year         = {2024}
}

@article{llama3,
  author       = {Abhimanyu Dubey and
                  Abhinav Jauhri and
                  Abhinav Pandey and
                  Abhishek Kadian and
                  Ahmad Al{-}Dahle and
                  Aiesha Letman and
                  Akhil Mathur and
                  Alan Schelten and
                  Amy Yang and
                  Angela Fan and
                  Anirudh Goyal and
                  Anthony Hartshorn and
                  Aobo Yang and
                  Archi Mitra and
                  Archie Sravankumar and
                  Artem Korenev and
                  Arthur Hinsvark and
                  Arun Rao and
                  Aston Zhang and
                  Aur{\'{e}}lien Rodriguez and
                  Austen Gregerson and
                  Ava Spataru and
                  Baptiste Rozi{\`{e}}re and
                  Bethany Biron and
                  Binh Tang and
                  Bobbie Chern and
                  Charlotte Caucheteux and
                  Chaya Nayak and
                  Chloe Bi and
                  Chris Marra and
                  Chris McConnell and
                  Christian Keller and
                  Christophe Touret and
                  Chunyang Wu and
                  Corinne Wong and
                  Cristian Canton Ferrer and
                  Cyrus Nikolaidis and
                  Damien Allonsius and
                  Daniel Song and
                  Danielle Pintz and
                  Danny Livshits and
                  David Esiobu and
                  Dhruv Choudhary and
                  Dhruv Mahajan and
                  Diego Garcia{-}Olano and
                  Diego Perino and
                  Dieuwke Hupkes and
                  Egor Lakomkin and
                  Ehab AlBadawy and
                  Elina Lobanova and
                  Emily Dinan and
                  Eric Michael Smith and
                  Filip Radenovic and
                  Frank Zhang and
                  Gabriel Synnaeve and
                  Gabrielle Lee and
                  Georgia Lewis Anderson and
                  Graeme Nail and
                  Gr{\'{e}}goire Mialon and
                  Guan Pang and
                  Guillem Cucurell and
                  Hailey Nguyen and
                  Hannah Korevaar and
                  Hu Xu and
                  Hugo Touvron and
                  Iliyan Zarov and
                  Imanol Arrieta Ibarra and
                  Isabel M. Kloumann and
                  Ishan Misra and
                  Ivan Evtimov and
                  Jade Copet and
                  Jaewon Lee and
                  Jan Geffert and
                  Jana Vranes and
                  Jason Park and
                  Jay Mahadeokar and
                  Jeet Shah and
                  Jelmer van der Linde and
                  Jennifer Billock and
                  Jenny Hong and
                  Jenya Lee and
                  Jeremy Fu and
                  Jianfeng Chi and
                  Jianyu Huang and
                  Jiawen Liu and
                  Jie Wang and
                  Jiecao Yu and
                  Joanna Bitton and
                  Joe Spisak and
                  Jongsoo Park and
                  Joseph Rocca and
                  Joshua Johnstun and
                  Joshua Saxe and
                  Junteng Jia and
                  Kalyan Vasuden Alwala and
                  Kartikeya Upasani and
                  Kate Plawiak and
                  Ke Li and
                  Kenneth Heafield and
                  Kevin Stone and
                  et al.},
  title        = {The {Llama} 3 Herd of Models},
  journal      = {CoRR},
  volume       = {abs/2407.21783},
  year         = {2024}
}

@article{mistral,
  author       = {Albert Q. Jiang and
                  Alexandre Sablayrolles and
                  Arthur Mensch and
                  Chris Bamford and
                  Devendra Singh Chaplot and
                  Diego de Las Casas and
                  Florian Bressand and
                  Gianna Lengyel and
                  Guillaume Lample and
                  Lucile Saulnier and
                  L{\'{e}}lio Renard Lavaud and
                  Marie{-}Anne Lachaux and
                  Pierre Stock and
                  Teven Le Scao and
                  Thibaut Lavril and
                  Thomas Wang and
                  Timoth{\'{e}}e Lacroix and
                  William El Sayed},
  title        = {Mistral {7B}},
  journal      = {CoRR},
  volume       = {abs/2310.06825},
  year         = {2023}
}

@article{mixtral,
  author       = {Albert Q. Jiang and
                  Alexandre Sablayrolles and
                  Antoine Roux and
                  Arthur Mensch and
                  Blanche Savary and
                  Chris Bamford and
                  Devendra Singh Chaplot and
                  Diego de Las Casas and
                  Emma Bou Hanna and
                  Florian Bressand and
                  Gianna Lengyel and
                  Guillaume Bour and
                  Guillaume Lample and
                  L{\'{e}}lio Renard Lavaud and
                  Lucile Saulnier and
                  Marie{-}Anne Lachaux and
                  Pierre Stock and
                  Sandeep Subramanian and
                  Sophia Yang and
                  Szymon Antoniak and
                  Teven Le Scao and
                  Th{\'{e}}ophile Gervet and
                  Thibaut Lavril and
                  Thomas Wang and
                  Timoth{\'{e}}e Lacroix and
                  William El Sayed},
  title        = {Mixtral of Experts},
  journal      = {CoRR},
  volume       = {abs/2401.04088},
  year         = {2024}
}

@techreport{gemini,
  title = {Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author = {{Gemini Team}},
  institution = {Google},
  url = {https://storage.googleapis.com/deepmind-media/gemini/gemini\_v1\_5\_report.pdf},
  year = {2024}
}

@article{gemma,
  author       = {Thomas Mesnard and Cassidy Hardin and Robert Dadashi and Surya Bhupatiraju and Shreya Pathak and Laurent Sifre and Morgane Rivière and Mihir Sanjay Kale and Juliette Love and Pouya Tafti and Léonard Hussenot and Pier Giuseppe Sessa and Aakanksha Chowdhery and Adam Roberts and Aditya Barua and Alex Botev and Alex Castro-Ros and Ambrose Slone and Amélie Héliou and Andrea Tacchetti and Anna Bulanova and Antonia Paterson and Beth Tsai and Bobak Shahriari and Charline Le Lan and Christopher A. Choquette-Choo and Clément Crepy and Daniel Cer and Daphne Ippolito and David Reid and Elena Buchatskaya and Eric Ni and Eric Noland and Geng Yan and George Tucker and George-Christian Muraru and Grigory Rozhdestvenskiy and Henryk Michalewski and Ian Tenney and Ivan Grishchenko and Jacob Austin and James Keeling and Jane Labanowski and Jean-Baptiste Lespiau and Jeff Stanway and Jenny Brennan and Jeremy Chen and Johan Ferret and Justin Chiu and Justin Mao-Jones and Katherine Lee and Kathy Yu and Katie Millican and Lars Lowe Sjoesund and Lisa Lee and Lucas Dixon and Machel Reid and Maciej Mikuła and Mateo Wirth and Michael Sharman and Nikolai Chinaev and Nithum Thain and Olivier Bachem and Oscar Chang and Oscar Wahltinez and Paige Bailey and Paul Michel and Petko Yotov and Rahma Chaabouni and Ramona Comanescu and Reena Jana and Rohan Anil and Ross McIlroy and Ruibo Liu and Ryan Mullins and Samuel L Smith and Sebastian Borgeaud and Sertan Girgin and Sholto Douglas and Shree Pandya and Siamak Shakeri and Soham De and Ted Klimenko and Tom Hennigan and Vlad Feinberg and Wojciech Stokowiec and Yu-hui Chen and Zafarali Ahmed and Zhitao Gong and Tris Warkentin and Ludovic Peran and Minh Giang and Clément Farabet and Oriol Vinyals and Jeff Dean and Koray Kavukcuoglu and Demis Hassabis and Zoubin Ghahramani and Douglas Eck and Joelle Barral and Fernando Pereira and Eli Collins and Armand Joulin and Noah Fiedel and Evan Senter and Alek Andreev and Kathleen Kenealy},
  title        = {Gemma: Open Models Based on {Gemini} Research and Technology},
  journal      = {CoRR},
  volume       = {abs/2403.08295},
  year         = {2024}
}

@article{deepseek,
author       = {Aixin Liu and
                  Bei Feng and
                  Bin Wang and
                  Bingxuan Wang and
                  Bo Liu and
                  Chenggang Zhao and
                  Chengqi Deng and
                  Chong Ruan and
                  Damai Dai and
                  Daya Guo and
                  Dejian Yang and
                  Deli Chen and
                  Dongjie Ji and
                  Erhang Li and
                  Fangyun Lin and
                  Fuli Luo and
                  Guangbo Hao and
                  Guanting Chen and
                  Guowei Li and
                  Hao Zhang and
                  Hanwei Xu and
                  Hao Yang and
                  Haowei Zhang and
                  Honghui Ding and
                  Huajian Xin and
                  Huazuo Gao and
                  Hui Li and
                  Hui Qu and
                  J. L. Cai and
                  Jian Liang and
                  Jianzhong Guo and
                  Jiaqi Ni and
                  Jiashi Li and
                  Jin Chen and
                  Jingyang Yuan and
                  Junjie Qiu and
                  Junxiao Song and
                  Kai Dong and
                  Kaige Gao and
                  Kang Guan and
                  Lean Wang and
                  Lecong Zhang and
                  Lei Xu and
                  Leyi Xia and
                  Liang Zhao and
                  Liyue Zhang and
                  Meng Li and
                  Miaojun Wang and
                  Mingchuan Zhang and
                  Minghua Zhang and
                  Minghui Tang and
                  Mingming Li and
                  Ning Tian and
                  Panpan Huang and
                  Peiyi Wang and
                  Peng Zhang and
                  Qihao Zhu and
                  Qinyu Chen and
                  Qiushi Du and
                  R. J. Chen and
                  R. L. Jin and
                  Ruiqi Ge and
                  Ruizhe Pan and
                  Runxin Xu and
                  Ruyi Chen and
                  S. S. Li and
                  Shanghao Lu and
                  Shangyan Zhou and
                  Shanhuang Chen and
                  Shaoqing Wu and
                  Shengfeng Ye and
                  Shirong Ma and
                  Shiyu Wang and
                  Shuang Zhou and
                  Shuiping Yu and
                  Shunfeng Zhou and
                  Size Zheng and
                  Tao Wang and
                  Tian Pei and
                  Tian Yuan and
                  Tianyu Sun and
                  W. L. Xiao and
                  Wangding Zeng and
                  Wei An and
                  Wen Liu and
                  Wenfeng Liang and
                  Wenjun Gao and
                  Wentao Zhang and
                  X. Q. Li and
                  Xiangyue Jin and
                  Xianzu Wang and
                  Xiao Bi and
                  Xiaodong Liu and
                  Xiaohan Wang and
                  Xiaojin Shen and
                  Xiaokang Chen and
                  Xiaosha Chen and
                  Xiaotao Nie and
                  Xiaowen Sun},
  title        = {{DeepSeek-V2}: A Strong, Economical, and Efficient Mixture-of-Experts
                  Language Model},
  journal      = {CoRR},
  volume       = {abs/2405.04434},
  year         = {2024}
}

@article{yi,
author       = {Alex Young and
                  Bei Chen and
                  Chao Li and
                  Chengen Huang and
                  Ge Zhang and
                  Guanwei Zhang and
                  Heng Li and
                  Jiangcheng Zhu and
                  Jianqun Chen and
                  Jing Chang and
                  Kaidong Yu and
                  Peng Liu and
                  Qiang Liu and
                  Shawn Yue and
                  Senbin Yang and
                  Shiming Yang and
                  Tao Yu and
                  Wen Xie and
                  Wenhao Huang and
                  Xiaohui Hu and
                  Xiaoyi Ren and
                  Xinyao Niu and
                  Pengcheng Nie and
                  Yuchi Xu and
                  Yudong Liu and
                  Yue Wang and
                  Yuxuan Cai and
                  Zhenyu Gu and
                  Zhiyuan Liu and
                  Zonghong Dai},
  title        = {Yi: Open Foundation Models by {01.AI}},
  journal      = {CoRR},
  volume       = {abs/2403.04652},
  year         = {2024}
}

@misc{dbrx,
  title = {Introducing {DBRX}: A New State-of-the-Art Open {LLM}},
  author = {{Mosaic Research Team}},
  url = {https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm},
  year = {2024}
}

@article{qwenaudio,
  author       = {Yunfei Chu and
                  Jin Xu and
                  Xiaohuan Zhou and
                  Qian Yang and
                  Shiliang Zhang and
                  Zhijie Yan and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {{Qwen-Audio}: Advancing Universal Audio Understanding via Unified Large-Scale
                  Audio-Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.07919},
  year         = {2023}
}

@inproceedings{mtbench,
  author       = {Lianmin Zheng and
                  Wei{-}Lin Chiang and
                  Ying Sheng and
                  Siyuan Zhuang and
                  Zhanghao Wu and
                  Yonghao Zhuang and
                  Zi Lin and
                  Zhuohan Li and
                  Dacheng Li and
                  Eric P. Xing and
                  Hao Zhang and
                  Joseph E. Gonzalez and
                  Ion Stoica},
  title        = {Judging {LLM}-as-a-Judge with {MT-Bench} and {Chatbot Arena}},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{humaneval,
  author       = {Mark Chen and
                  Jerry Tworek and
                  Heewoo Jun and
                  Qiming Yuan and
                  Henrique Pond{\'{e}} de Oliveira Pinto and
                  Jared Kaplan and
                  Harrison Edwards and
                  Yuri Burda and
                  Nicholas Joseph and
                  Greg Brockman and
                  Alex Ray and
                  Raul Puri and
                  Gretchen Krueger and
                  Michael Petrov and
                  Heidy Khlaaf and
                  Girish Sastry and
                  Pamela Mishkin and
                  Brooke Chan and
                  Scott Gray and
                  Nick Ryder and
                  Mikhail Pavlov and
                  Alethea Power and
                  Lukasz Kaiser and
                  Mohammad Bavarian and
                  Clemens Winter and
                  Philippe Tillet and
                  Felipe Petroski Such and
                  Dave Cummings and
                  Matthias Plappert and
                  Fotios Chantzis and
                  Elizabeth Barnes and
                  Ariel Herbert{-}Voss and
                  William Hebgen Guss and
                  Alex Nichol and
                  Alex Paino and
                  Nikolas Tezak and
                  Jie Tang and
                  Igor Babuschkin and
                  Suchir Balaji and
                  Shantanu Jain and
                  William Saunders and
                  Christopher Hesse and
                  Andrew N. Carr and
                  Jan Leike and
                  Joshua Achiam and
                  Vedant Misra and
                  Evan Morikawa and
                  Alec Radford and
                  Matthew Knight and
                  Miles Brundage and
                  Mira Murati and
                  Katie Mayer and
                  Peter Welinder and
                  Bob McGrew and
                  Dario Amodei and
                  Sam McCandlish and
                  Ilya Sutskever and
                  Wojciech Zaremba},
  title        = {Evaluating Large Language Models Trained on Code},
  journal      = {CoRR},
  volume       = {abs/2107.03374},
  year         = {2021}
}

@article{gpqa,
  author       = {David Rein and
                  Betty Li Hou and
                  Asa Cooper Stickland and
                  Jackson Petty and
                  Richard Yuanzhe Pang and
                  Julien Dirani and
                  Julian Michael and
                  Samuel R. Bowman},
  title        = {{GPQA}: A Graduate-Level {Google}-Proof {Q}{\&}{A} Benchmark},
  journal      = {CoRR},
  volume       = {abs/2311.12022},
  year         = {2023}
}

@inproceedings{theoremqa,
  author       = {Wenhu Chen and
                  Ming Yin and
                  Max Ku and
                  Pan Lu and
                  Yixin Wan and
                  Xueguang Ma and
                  Jianyu Xu and
                  Xinyi Wang and
                  Tony Xia},
  title        = {{TheoremQA}: A Theorem-driven Question Answering Dataset},
  booktitle    = {{EMNLP}},
  pages        = {7889--7901},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{alpacaeval,
  author       = {Yann Dubois and
                  Bal{\'{a}}zs Galambosi and
                  Percy Liang and
                  Tatsunori B. Hashimoto},
  title        = {Length-Controlled AlpacaEval: {A} Simple Way to Debias Automatic Evaluators},
  journal      = {CoRR},
  volume       = {abs/2404.04475},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2404.04475},
  doi          = {10.48550/ARXIV.2404.04475},
  eprinttype    = {arXiv},
  eprint       = {2404.04475},
  timestamp    = {Wed, 15 May 2024 08:47:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2404-04475.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ifeval,
  author       = {Jeffrey Zhou and
                  Tianjian Lu and
                  Swaroop Mishra and
                  Siddhartha Brahma and
                  Sujoy Basu and
                  Yi Luan and
                  Denny Zhou and
                  Le Hou},
  title        = {Instruction-Following Evaluation for Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.07911},
  year         = {2023}
}

@article{multiple,
  author       = {Federico Cassano and
                  John Gouwar and
                  Daniel Nguyen and
                  Sydney Nguyen and
                  Luna Phipps{-}Costin and
                  Donald Pinckney and
                  Ming{-}Ho Yee and
                  Yangtian Zi and
                  Carolyn Jane Anderson and
                  Molly Q. Feldman and
                  Arjun Guha and
                  Michael Greenberg and
                  Abhinav Jangda},
  title        = {{MultiPL-E}: {A} Scalable and Polyglot Approach to Benchmarking Neural
                  Code Generation},
  journal      = {{IEEE} Trans. Software Eng.},
  volume       = {49},
  number       = {7},
  pages        = {3675--3691},
  year         = {2023}
}

@article{mmlupro,
  author       = {Yubo Wang and
                  Xueguang Ma and
                  Ge Zhang and
                  Yuansheng Ni and
                  Abhranil Chandra and
                  Shiguang Guo and
                  Weiming Ren and
                  Aaran Arulraj and
                  Xuan He and
                  Ziyan Jiang and
                  Tianle Li and
                  Max Ku and
                  Kai Wang and
                  Alex Zhuang and
                  Rongqi Fan and
                  Xiang Yue and
                  Wenhu Chen},
  title        = {{MMLU-Pro}: {A} More Robust and Challenging Multi-Task Language Understanding
                  Benchmark},
  journal      = {CoRR},
  volume       = {abs/2406.01574},
  year         = {2024}
}

@article{winogrande,
  author       = {Keisuke Sakaguchi and
                  Ronan Le Bras and
                  Chandra Bhagavatula and
                  Yejin Choi},
  title        = {{WinoGrande}: An adversarial winograd schema challenge at scale},
  journal      = {Commun. {ACM}},
  volume       = {64},
  number       = {9},
  pages        = {99--106},
  year         = {2021}
}

@inproceedings{truthfulqa,
  author       = {Stephanie Lin and
                  Jacob Hilton and
                  Owain Evans},
  title        = {{TruthfulQA}: Measuring How Models Mimic Human Falsehoods},
  booktitle    = {{ACL} {(1)}},
  pages        = {3214--3252},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@article{jamba,
  author       = {Opher Lieber and
                  Barak Lenz and
                  Hofit Bata and
                  Gal Cohen and
                  Jhonathan Osin and
                  Itay Dalmedigos and
                  Erez Safahi and
                  Shaked Meirom and
                  Yonatan Belinkov and
                  Shai Shalev{-}Shwartz and
                  Omri Abend and
                  Raz Alon and
                  Tomer Asida and
                  Amir Bergman and
                  Roman Glozman and
                  Michael Gokhman and
                  Avashalom Manevich and
                  Nir Ratner and
                  Noam Rozen and
                  Erez Shwartz and
                  Mor Zusman and
                  Yoav Shoham},
  title        = {Jamba: A Hybrid {Transformer-Mamba} Language Model},
  journal      = {CoRR},
  volume       = {abs/2403.19887},
  year         = {2024}
}

@misc{codeqwen,
      title={{Code with CodeQwen1.5}}, 
      author={{Qwen~Team}},
      year={2024},
      url={https://qwenlm.github.io/blog/codeqwen1.5/}
}

@misc{phi2,
      title={Phi-2: The surprising power of small language models}, 
      author={Marah Abdin and Jyoti Aneja and Sebastien Bubeck and Caio César Teodoro Mendes and Weizhu Chen and Allie Del Giorno and Ronen Eldan and Sivakanth Gopi and Suriya Gunasekar and Mojan Javaheripi and Piero Kauffmann and Yin Tat Lee and Yuanzhi Li and Anh Nguyen and Gustavo de Rosa and Olli Saarikivi and Adil Salim and Shital Shah and Michael Santacroce and Harkirat Singh Behl and Adam Taumann Kalai and Xin Wang and Rachel Ward and Philipp Witte and Cyril Zhang and Yi Zhang},
      year={2024},
      url={https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/}
}

@article{minicpm,
  author       = {Shengding Hu and
                  Yuge Tu and
                  Xu Han and
                  Chaoqun He and
                  Ganqu Cui and
                  Xiang Long and
                  Zhi Zheng and
                  Yewei Fang and
                  Yuxiang Huang and
                  Weilin Zhao and
                  Xinrong Zhang and
                  Zhen Leng Thai and
                  Kai Zhang and
                  Chongyi Wang and
                  Yuan Yao and
                  Chenyang Zhao and
                  Jie Zhou and
                  Jie Cai and
                  Zhongwu Zhai and
                  Ning Ding and
                  Chao Jia and
                  Guoyang Zeng and
                  Dahai Li and
                  Zhiyuan Liu and
                  Maosong Sun},
  title        = {{MiniCPM}: Unveiling the Potential of Small Language Models with Scalable
                  Training Strategies},
  journal      = {CoRR},
  volume       = {abs/2404.06395},
  year         = {2024}
}

@article{phi3,
  author       = {Marah I Abdin and
                  Sam Ade Jacobs and
                  Ammar Ahmad Awan and
                  Jyoti Aneja and
                  Ahmed Awadallah and
                  Hany Awadalla and
                  Nguyen Bach and
                  Amit Bahree and
                  Arash Bakhtiari and
                  Harkirat S. Behl and
                  Alon Benhaim and
                  Misha Bilenko and
                  Johan Bjorck and
                  S{\'{e}}bastien Bubeck and
                  Martin Cai and
                  Caio C{\'{e}}sar Teodoro Mendes and
                  Weizhu Chen and
                  Vishrav Chaudhary and
                  Parul Chopra and
                  Allie Del Giorno and
                  Gustavo de Rosa and
                  Matthew Dixon and
                  Ronen Eldan and
                  Dan Iter and
                  Amit Garg and
                  Abhishek Goswami and
                  Suriya Gunasekar and
                  Emman Haider and
                  Junheng Hao and
                  Russell J. Hewett and
                  Jamie Huynh and
                  Mojan Javaheripi and
                  Xin Jin and
                  Piero Kauffmann and
                  Nikos Karampatziakis and
                  Dongwoo Kim and
                  Mahoud Khademi and
                  Lev Kurilenko and
                  James R. Lee and
                  Yin Tat Lee and
                  Yuanzhi Li and
                  Chen Liang and
                  Weishung Liu and
                  Eric Lin and
                  Zeqi Lin and
                  Piyush Madan and
                  Arindam Mitra and
                  Hardik Modi and
                  Anh Nguyen and
                  Brandon Norick and
                  Barun Patra and
                  Daniel Perez{-}Becker and
                  Thomas Portet and
                  Reid Pryzant and
                  Heyang Qin and
                  Marko Radmilac and
                  Corby Rosset and
                  Sambudha Roy and
                  Olatunji Ruwase and
                  Olli Saarikivi and
                  Amin Saied and
                  Adil Salim and
                  Michael Santacroce and
                  Shital Shah and
                  Ning Shang and
                  Hiteshi Sharma and
                  Xia Song and
                  Masahiro Tanaka and
                  Xin Wang and
                  Rachel Ward and
                  Guanhua Wang and
                  Philipp Witte and
                  Michael Wyatt and
                  Can Xu and
                  Jiahang Xu and
                  Sonali Yadav and
                  Fan Yang and
                  Ziyi Yang and
                  Donghan Yu and
                  Chengruidong Zhang and
                  Cyril Zhang and
                  Jianwen Zhang and
                  Li Lyna Zhang and
                  Yi Zhang and
                  Yue Zhang and
                  Yunan Zhang and
                  Xiren Zhou},
  title        = {Phi-3 Technical Report: {A} Highly Capable Language Model Locally
                  on Your Phone},
  journal      = {CoRR},
  volume       = {abs/2404.14219},
  year         = {2024}
}

@misc{niah,
      title={Needle in a haystack - Pressure testing {LLMs}}, 
      author={Gregory Kamradt},
      year={2023},
      url={https://github.com/gkamradt/LLMTest_NeedleInAHaystack}
}

@article{yuan2024lveval,
  author       = {Tao Yuan and
                  Xuefei Ning and
                  Dong Zhou and
                  Zhijie Yang and
                  Shiyao Li and
                  Minghui Zhuang and
                  Zheyue Tan and
                  Zhuyu Yao and
                  Dahua Lin and
                  Boxun Li and
                  Guohao Dai and
                  Shengen Yan and
                  Yu Wang},
  title        = {{LV-Eval}: {A} Balanced Long-Context Benchmark with 5 Length Levels
                  Up to {256K}},
  journal      = {CoRR},
  volume       = {abs/2402.05136},
  year         = {2024}
}

@article{chatglm4,
    title={{ChatGLM}: A Family of Large Language Models from {GLM-130B} to {GLM-4} All Tools},
    author={Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},
  journal      = {CoRR},
  volume       = {abs/2406.12793},
  year         = {2024}
}

@inproceedings{wang2020neural,
  author       = {Changhan Wang and
                  Kyunghyun Cho and
                  Jiatao Gu},
  title        = {Neural Machine Translation with Byte-Level Subwords},
  booktitle    = {{AAAI}},
  pages        = {9154--9160},
  publisher    = {{AAAI} Press},
  year         = {2020}
}

@inproceedings{sennirch2016neural,
  author       = {Rico Sennrich and
                  Barry Haddow and
                  Alexandra Birch},
  title        = {Neural Machine Translation of Rare Words with Subword Units},
  booktitle    = {{ACL} {(1)}},
  publisher    = {The Association for Computer Linguistics},
  year         = {2016}
}

@article{hsieh2024ruler,
  title={{RULER}: What's the Real Context Size of Your Long-Context Language Models?},
  author={Cheng-Ping Hsieh and Simeng Sun and Samuel Kriman and Shantanu Acharya and Dima Rekesh and Fei Jia and Yang Zhang and Boris Ginsburg},
  year={2024},
  journal={CoRR},
  volume={abs/2404.06654},
}



@inproceedings{longalign2024bai,
  author       = {Yushi Bai and
                  Xin Lv and
                  Jiajie Zhang and
                  Yuze He and
                  Ji Qi and
                  Lei Hou and
                  Jie Tang and
                  Yuxiao Dong and
                  Juanzi Li},
  title        = {{LongAlign}: {A} Recipe for Long Context Alignment of Large Language
                  Models},
  booktitle    = {{EMNLP} (Findings)},
  pages        = {1376--1395},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@article{livebench,
  author    = {Colin White and
                  Samuel Dooley and
                  Manley Roberts and
                  Arka Pal and
                  Benjamin Feuer and
                  Siddhartha Jain and
                  Ravid Shwartz{-}Ziv and
                  Neel Jain and
                  Khalid Saifullah and
                  Siddartha Naidu and
                  Chinmay Hegde and
                  Yann LeCun and
                  Tom Goldstein and
                  Willie Neiswanger and
                  Micah Goldblum},
  title     = {{LiveBench}: A Challenging, Contamination-Free {LLM} Benchmark},
  year      = {2024},
  journal   = {CoRR},
  volume    = {abs/2406.19314}
}

@article{blend,
  author       = {Junho Myung and
                  Nayeon Lee and
                  Yi Zhou and
                  Jiho Jin and
                  Rifki Afina Putri and
                  Dimosthenis Antypas and
                  Hsuvas Borkakoty and
                  Eunsu Kim and
                  Carla P{\'{e}}rez{-}Almendros and
                  Abinew Ali Ayele and
                  V{\'{\i}}ctor Guti{\'{e}}rrez{-}Basulto and
                  Yazm{\'{\i}}n Ib{\'{a}}{\~{n}}ez{-}Garc{\'{\i}}a and
                  Hwaran Lee and
                  Shamsuddeen Hassan Muhammad and
                  Ki{-}Woong Park and
                  Anar Sabuhi Rzayev and
                  Nina White and
                  Seid Muhie Yimam and
                  Mohammad Taher Pilehvar and
                  Nedjma Ousidhoum and
                  Jos{\'{e}} Camacho{-}Collados and
                  Alice Oh},
  title        = {BLEnD: {A} Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages},
  year         = {2024},
  journal      = {CoRR},
  volume       = {abs/2406.09948}
}

@article{jiang2024minference,
    title={MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention},
    author={Jiang, Huiqiang and Li, Yucheng and Zhang, Chengruidong and Wu, Qianhui and Luo, Xufang and Ahn, Surin and Han, Zhenhua and Abdi, Amir H and Li, Dongsheng and Lin, Chin-Yew and Yang, Yuqing and Qiu, Lili},
    journal={arXiv preprint arXiv:2407.02490},
    year={2024}
}

@InProceedings{pmlr-v202-dehghani23a,
  author       = {Mostafa Dehghani and
                  Josip Djolonga and
                  Basil Mustafa and
                  Piotr Padlewski and
                  Jonathan Heek and
                  Justin Gilmer and
                  Andreas Peter Steiner and
                  Mathilde Caron and
                  Robert Geirhos and
                  Ibrahim Alabdulmohsin and
                  Rodolphe Jenatton and
                  Lucas Beyer and
                  Michael Tschannen and
                  Anurag Arnab and
                  Xiao Wang and
                  Carlos Riquelme Ruiz and
                  Matthias Minderer and
                  Joan Puigcerver and
                  Utku Evci and
                  Manoj Kumar and
                  Sjoerd van Steenkiste and
                  Gamaleldin Fathy Elsayed and
                  Aravindh Mahendran and
                  Fisher Yu and
                  Avital Oliver and
                  Fantine Huot and
                  Jasmijn Bastings and
                  Mark Collier and
                  Alexey A. Gritsenko and
                  Vighnesh Birodkar and
                  Cristina Nader Vasconcelos and
                  Yi Tay and
                  Thomas Mensink and
                  Alexander Kolesnikov and
                  Filip Pavetic and
                  Dustin Tran and
                  Thomas Kipf and
                  Mario Lucic and
                  Xiaohua Zhai and
                  Daniel Keysers and
                  Jeremiah J. Harmsen and
                  Neil Houlsby},
  title        = {Scaling Vision Transformers to 22 Billion Parameters},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {7480--7512},
  publisher    = {{PMLR}},
  year         = {2023}
}

@article{global_balance,
  author       = {Zihan Qiu and
                  Zeyu Huang and
                  Bo Zheng and
                  Kaiyue Wen and
                  Zekun Wang and
                  Rui Men and
                  Ivan Titov and
                  Dayiheng Liu and
                  Jingren Zhou and
                  Junyang Lin},
  title        = {Demons in the Detail: On Implementing Load Balancing Loss for Training
                  Specialized Mixture-of-Expert Models},
  journal      = {CoRR},
  volume       = {abs/2501.11873},
  year         = {2025}
}

@article{gu2024cruxeval,
  title={{CRUXEval}: A Benchmark for Code Reasoning, Understanding and Execution}, 
  author={Alex Gu and Baptiste Rozière and Hugh Leather and Armando Solar-Lezama and Gabriel Synnaeve and Sida I. Wang},
  year={2024},
  journal = {arXiv preprint arXiv:2401.03065},
}

@misc{mmmlu,
  author       = {OpenAI},
  title        = {Multilingual Massive Multitask Language Understanding},
  year = {2024},
  url = {https://huggingface.co/datasets/openai/MMMLU}

}
@article{romanou2024includeevaluatingmultilinguallanguage,
  author       = {Angelika Romanou and
                  Negar Foroutan and
                  Anna Sotnikova and
                  Zeming Chen and
                  Sree Harsha Nelaturu and
                  Shivalika Singh and
                  Rishabh Maheshwary and
                  Micol Altomare and
                  Mohamed A. Haggag and
                  Snegha A and
                  Alfonso Amayuelas and
                  Azril Hafizi Amirudin and
                  Viraat Aryabumi and
                  Danylo Boiko and
                  Michael Chang and
                  Jenny Chim and
                  Gal Cohen and
                  Aditya Kumar Dalmia and
                  Abraham Diress and
                  Sharad Duwal and
                  Daniil Dzenhaliou and
                  Daniel Fernando Erazo Florez and
                  Fabian Farestam and
                  Joseph Marvin Imperial and
                  Shayekh Bin Islam and
                  Perttu Isotalo and
                  Maral Jabbarishiviari and
                  B{\"{o}}rje F. Karlsson and
                  Eldar Khalilov and
                  Christopher Klamm and
                  Fajri Koto and
                  Dominik Krzeminski and
                  Gabriel Adriano de Melo and
                  Syrielle Montariol and
                  Yiyang Nan and
                  Joel Niklaus and
                  Jekaterina Novikova and
                  Johan Samir Obando Ceron and
                  Debjit Paul and
                  Esther Ploeger and
                  Jebish Purbey and
                  Swati Rajwal and
                  Selvan Sunitha Ravi and
                  Sara Rydell and
                  Roshan Santhosh and
                  Drishti Sharma and
                  Marjana Prifti Skenduli and
                  Arshia Soltani Moakhar and
                  Bardia Soltani Moakhar and
                  Ran Tamir and
                  Ayush Kumar Tarun and
                  Azmine Toushik Wasi and
                  Thenuka Ovin Weerasinghe and
                  Serhan Yilmaz and
                  Mike Zhang and
                  Imanol Schlag and
                  Marzieh Fadaee and
                  Sara Hooker and
                  Antoine Bosselut},
  title        = {{INCLUDE:} Evaluating Multilingual Language Understanding with Regional
                  Knowledge},
  journal      = {CoRR},
  volume       = {abs/2411.19799},
  year         = {2024}
}



@article{son2025linguisticgeneralizabilitytesttimescaling,
  author       = {Guijin Son and
                  Jiwoo Hong and
                  Hyunwoo Ko and
                  James Thorne},
  title        = {Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning},
  journal      = {CoRR},
  volume       = {abs/2502.17407},
  year         = {2025}
}


@misc{wang2025polymathevaluatingmathematicalreasoning,
      title={{PolyMath}: Evaluating Mathematical Reasoning in Multilingual Contexts}, 
      author={Yiming Wang and Pei Zhang and Jialong Tang and Haoran Wei and Baosong Yang and Rui Wang and Chenshu Sun and Feitong Sun and Jiran Zhang and Junxuan Wu and Qiqian Cang and Yichang Zhang and Fei Huang and Junyang Lin and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2504.18428}
}

@article{he2024multi,
  title={{Multi-IF}: Benchmarking {LLMs} on Multi-Turn and Multilingual Instructions Following},
  author={He, Yun and Jin, Di and Wang, Chaoqi and Bi, Chloe and Mandyam, Karishma and Zhang, Hejia and Zhu, Chen and Li, Ning and Xu, Tengyu and Lv, Hongjiang and others},
  journal={arXiv preprint arXiv:2410.15553},
  year={2024}
}



@misc{creative_writing,
      title={Creative Writing v3}, 
      author={Samuel J. Paech},
      year={2024},
      url={https://eqbench.com/creative_writing.html}
}

@misc{kimi_researcher,
      title={KIMI Researcher tech report}, 
      author={Kimi Team},
      year={2025},
      url={https://moonshotai.github.io/Kimi-Researcher/}
}

@article{xue2025simpletir,
  title={Simpletir: End-to-end reinforcement learning for multi-turn tool-integrated reasoning},
  author={Xue, Zhenghai and Zheng, Longtao and Liu, Qian and Li, Yingru and Zheng, Xiaosen and Ma, Zejun and An, Bo},
  journal={arXiv preprint arXiv:2509.02479},
  year={2025}
}





@article{writingbench,
  author       = {Yuning Wu and
                  Jiahao Mei and
                  Ming Yan and
                  Chenliang Li and
                  Shaopeng Lai and
                  Yuran Ren and
                  Zijia Wang and
                  Ji Zhang and
                  Mengyue Wu and
                  Qin Jin and
                  Fei Huang},
  title        = {{WritingBench}: {A} Comprehensive Benchmark for Generative Writing},
  journal      = {CoRR},
  volume       = {abs/2503.05244},
  year         = {2025}
}

@misc{aime,
      title={{AIME} Problems and Solutions},
      author={{AIME}},
      year={2025},
      url={https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions}
}




@article{zebralogic,
  author       = {Bill Yuchen Lin and
                  Ronan Le Bras and
                  Kyle Richardson and
                  Ashish Sabharwal and
                  Radha Poovendran and
                  Peter Clark and
                  Yejin Choi},
  title        = {{ZebraLogic}: On the Scaling Limits of {LLMs} for Logical Reasoning},
  journal      = {CoRR},
  volume       = {abs/2502.01100},
  year         = {2025}
}




@article{autologi,
  author       = {Qin Zhu and
                  Fei Huang and
                  Runyu Peng and
                  Keming Lu and
                  Bowen Yu and
                  Qinyuan Cheng and
                  Xipeng Qiu and
                  Xuanjing Huang and
                  Junyang Lin},
  title        = {{AutoLogi}: Automated Generation of Logic Puzzles for Evaluating Reasoning
                  Abilities of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2502.16906},
  year         = {2025}
}

@misc{bfcl,
    title={Berkeley Function Calling Leaderboard}, 
    author={Fanjia Yan and Huanzhi Mao and Charlie Cheng-Jie Ji
    and Tianjun Zhang and Shishir G. Patil and Ion Stoica and Joseph E.
    Gonzalez},
    howpublished={\url{https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html}},
    year={2024},
}



@article{codelo,
  author       = {Shanghaoran Quan and
                  Jiaxi Yang and
                  Bowen Yu and
                  Bo Zheng and
                  Dayiheng Liu and
                  An Yang and
                  Xuancheng Ren and
                  Bofei Gao and
                  Yibo Miao and
                  Yunlong Feng and
                  Zekun Wang and
                  Jian Yang and
                  Zeyu Cui and
                  Yang Fan and
                  Yichang Zhang and
                  Binyuan Hui and
                  Junyang Lin},
  title        = {{CodeElo}: Benchmarking Competition-level Code Generation of {LLMs} with
                  Human-comparable {Elo} Ratings},
  journal      = {CoRR},
  volume       = {abs/2501.01257},
  year         = {2025}
}

@misc{fang2025generalagenticintelligenceenvironment,
      title={Towards General Agentic Intelligence via Environment Scaling}, 
      author={Runnan Fang and Shihao Cai and Baixuan Li and Jialong Wu and Guangyu Li and Wenbiao Yin and Xinyu Wang and Xiaobin Wang and Liangcai Su and Zhen Zhang and Shibin Wu and Zhengwei Tao and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2509.13311},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2509.13311}, 
}

@misc{su2025scalingagentscontinualpretraining,
      title={Scaling Agents via Continual Pre-training}, 
      author={Liangcai Su and Zhen Zhang and Guangyu Li and Zhuo Chen and Chenxi Wang and Maojia Song and Xinyu Wang and Kuan Li and Jialong Wu and Xuanzhong Chen and Zile Qiao and Zhongwang Zhang and Huifeng Yin and Shihao Cai and Runnan Fang and Zhengwei Tao and Wenbiao Yin and Chenxiong Qian and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2509.13310},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2509.13310}, 
}

@article{tulu3,
  author       = {Nathan Lambert and
                  Jacob Morrison and
                  Valentina Pyatkin and
                  Shengyi Huang and
                  Hamish Ivison and
                  Faeze Brahman and
                  Lester James V. Miranda and
                  Alisa Liu and
                  Nouha Dziri and
                  Shane Lyu and
                  Yuling Gu and
                  Saumya Malik and
                  Victoria Graf and
                  Jena D. Hwang and
                  Jiangjiang Yang and
                  Ronan Le Bras and
                  Oyvind Tafjord and
                  Chris Wilhelm and
                  Luca Soldaini and
                  Noah A. Smith and
                  Yizhong Wang and
                  Pradeep Dasigi and
                  Hannaneh Hajishirzi},
  title        = {T{\"{U}}LU 3: Pushing Frontiers in Open Language Model Post-Training},
  journal      = {CoRR},
  volume       = {abs/2411.15124},
  year         = {2024}
}


@misc{webwalker,
      title={WebWalker: Benchmarking LLMs in Web Traversal}, 
      author={Jialong Wu and Wenbiao Yin and Yong Jiang and Zhenglin Wang and Zekun Xi and Runnan Fang and Linhai Zhang and Yulan He and Deyu Zhou and Pengjun Xie and Fei Huang},
      year={2025},
      eprint={2501.07572},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.07572}, 
}

@article{yin2025towards,
  title={Towards widening the distillation bottleneck for reasoning models},
  author={Yin, Huifeng and Zhao, Yu and Wu, Minghao and Ni, Xuanfan and Zeng, Bo and Wang, Hao and Shi, Tianqi and Shao, Liangying and Lyu, Chenyang and Wang, Longyue and others},
  journal={arXiv e-prints},
  pages={arXiv--2503},
  year={2025}
}

@misc{evolvesearch,
      title={EvolveSearch: An Iterative Self-Evolving Search Agent}, 
      author={Dingchu Zhang and Yida Zhao and Jialong Wu and Baixuan Li and Wenbiao Yin and Liwen Zhang and Yong Jiang and Yufeng Li and Kewei Tu and Pengjun Xie and Fei Huang},
      year={2025},
      eprint={2505.22501},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.22501}, 
}

@misc{zheng2025deepresearch,
      title={DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments}, 
      author={Yuxiang Zheng and Dayuan Fu and Xiangkun Hu and Xiaojie Cai and Lyumanshan Ye and Pengrui Lu and Pengfei Liu},
      year={2025},
      eprint={2504.03160},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.03160}, 
}

@article{zhang2025nemotron,
  title={Nemotron-Research-Tool-N1: Tool-Using Language Models with Reinforced Reasoning},
  author={Zhang, Shaokun and Dong, Yi and Zhang, Jieyu and Kautz, Jan and Catanzaro, Bryan and Tao, Andrew and Wu, Qingyun and Yu, Zhiding and Liu, Guilin},
  journal={arXiv preprint arXiv:2505.00024},
  year={2025}
}

@article{sun2025simpledeepsearcher,
  title={SimpleDeepSearcher: Deep information seeking via web-powered reasoning trajectory synthesis},
  author={Sun, Shuang and Song, Huatong and Wang, Yuhao and Ren, Ruiyang and Jiang, Jinhao and Zhang, Junjie and Bai, Fei and Deng, Jia and Zhao, Wayne Xin and Liu, Zheng and others},
  journal={arXiv preprint arXiv:2505.16834},
  year={2025}
}


@article{kwiatkowskinatural,
  title={Natural Questions: a Benchmark for Question Answering Research},
  author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others}
}

@article{wu2023autogen,
  title={Autogen: Enabling next-gen llm applications via multi-agent conversation},
  author={Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and others},
  journal={arXiv preprint arXiv:2308.08155},
  year={2023}
}

@article{guo2024large,
  title={Large language model based multi-agents: A survey of progress and challenges},
  author={Guo, Taicheng and Chen, Xiuying and Wang, Yaqi and Chang, Ruidi and Pei, Shichao and Chawla, Nitesh V and Wiest, Olaf and Zhang, Xiangliang},
  journal={arXiv preprint arXiv:2402.01680},
  year={2024}
}

@article{wang2024survey,
  title={A survey on large language model based autonomous agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  pages={186345},
  year={2024},
  publisher={Springer}
}
@misc{zhu2025oagents,
      title={OAgents: An Empirical Study of Building Effective Agents}, 
      author={He Zhu and Tianrui Qin and King Zhu and Heyuan Huang and Yeyi Guan and Jinxiang Xia and Yi Yao and Hanhao Li and Ningning Wang and Pai Liu and Tianhao Peng and Xin Gui and Xiaowan Li and Yuhui Liu and Yuchen Eleanor Jiang and Jun Wang and Changwang Zhang and Xiangru Tang and Ge Zhang and Jian Yang and Minghao Liu and Xitong Gao and Jiaheng Liu and Wangchunshu Zhou},
      year={2025},
      eprint={2506.15741},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.15741}, 
}

@misc{sun2025simpleds,
      title={SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis}, 
      author={Shuang Sun and Huatong Song and Yuhao Wang and Ruiyang Ren and Jinhao Jiang and Junjie Zhang and Fei Bai and Jia Deng and Wayne Xin Zhao and Zheng Liu and Lei Fang and Zhongyuan Wang and Ji-Rong Wen},
      year={2025},
      eprint={2505.16834},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.16834}, 
}

@misc{zheng2025deepresearcher,
      title={DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments}, 
      author={Yuxiang Zheng and Dayuan Fu and Xiangkun Hu and Xiaojie Cai and Lyumanshan Ye and Pengrui Lu and Pengfei Liu},
      year={2025},
      eprint={2504.03160},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.03160}, 
}

@misc{shi2025pangu,
      title={Pangu DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement Learning}, 
      author={Wenxuan Shi and Haochen Tan and Chuqiao Kuang and Xiaoguang Li and Xiaozhe Ren and Chen Zhang and Hanting Chen and Yasheng Wang and Lifeng Shang and Fisher Yu and Yunhe Wang},
      year={2025},
      eprint={2505.24332},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.24332}, 
}

@misc{chen2025research,
      title={ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning}, 
      author={Mingyang Chen and Tianpeng Li and Haoze Sun and Yijie Zhou and Chenzheng Zhu and Haofen Wang and Jeff Z. Pan and Wen Zhang and Huajun Chen and Fan Yang and Zenan Zhou and Weipeng Chen},
      year={2025},
      eprint={2503.19470},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2503.19470}, 
}


@misc{zhang2025evolvesearch,
      title={EvolveSearch: An Iterative Self-Evolving Search Agent}, 
      author={Dingchu Zhang and Yida Zhao and Jialong Wu and Baixuan Li and Wenbiao Yin and Liwen Zhang and Yong Jiang and Yufeng Li and Kewei Tu and Pengjun Xie and Fei Huang},
      year={2025},
      eprint={2505.22501},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.22501}, 
}

@misc{wu2025masksearchuniversalpretrainingframework,
      title={MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability}, 
      author={Weiqi Wu and Xin Guan and Shen Huang and Yong Jiang and Pengjun Xie and Fei Huang and Jiuxin Cao and Hai Zhao and Jingren Zhou},
      year={2025},
      eprint={2505.20285},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.20285}, 
}

@misc{xbench,
  title = {Xbench-DeepSearch},
  author = {Xbench-Team},
  url = {https://xbench.org/agi/aisearch},
  year={2025}
}

@article{wong2025widesearch,
  title={WideSearch: Benchmarking Agentic Broad Info-Seeking},
  author={Wong, Ryan and Wang, Jiawei and Zhao, Junjie and Chen, Li and Gao, Yan and Zhang, Long and Zhou, Xuan and Wang, Zuo and Xiang, Kai and Zhang, Ge and others},
  journal={arXiv preprint arXiv:2508.07999},
  year={2025}
}

@article{pham2025sealqa,
  title={SealQA: Raising the Bar for Reasoning in Search-Augmented Language Models},
  author={Pham, Thinh and Nguyen, Nguyen and Zunjare, Pratibha and Chen, Weiyuan and Tseng, Yu-Min and Vu, Tu},
  journal={arXiv preprint arXiv:2506.01062},
  year={2025}
}

@article{deepdiver-v2,
  title={Openpangu deepdiver-v2: Multi-agent learning for deep information seeking, 2025b},
  author={Team, OpenPangu},
  journal={URL https://ai. gitcode. com/ascend-tribe/openPangu-Embedded-7B-DeepDiver}
}

@article{kimi-k2,
  title={Kimi k2: Open agentic intelligence},
  author={Team, Kimi and Bai, Yifan and Bao, Yiping and Chen, Guanduo and Chen, Jiahao and Chen, Ningxin and Chen, Ruijue and Chen, Yanru and Chen, Yuankun and Chen, Yutian and others},
  journal={arXiv preprint arXiv:2507.20534},
  year={2025}
}

@article{liu2025webexplorer,
  title={Webexplorer: Explore and evolve for training long-horizon web agents},
  author={Liu, Junteng and Li, Yunji and Zhang, Chi and Li, Jingyang and Chen, Aili and Ji, Ke and Cheng, Weiyu and Wu, Zijia and Du, Chengyu and Xu, Qidi and others},
  journal={arXiv preprint arXiv:2509.06501},
  year={2025}
}

@article{asearcher,
  title={Beyond ten turns: Unlocking long-horizon agentic search with large-scale asynchronous rl},
  author={Gao, Jiaxuan and Fu, Wei and Xie, Minyang and Xu, Shusheng and He, Chuyi and Mei, Zhiyu and Zhu, Banghua and Wu, Yi},
  journal={arXiv preprint arXiv:2508.07976},
  year={2025}
}

@misc{miromind2025mirothinker,
  title={Mirothinker: An open-source agentic model series trained for deep research and complex, long-horizon problem solving},
  author={MiroMind AI Team and others},
  year={2025}
}

@article{lu2025deepdive,
  title={DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL},
  author={Lu, Rui and Hou, Zhenyu and Wang, Zihan and Zhang, Hanchen and Liu, Xiao and Li, Yujiang and Feng, Shi and Tang, Jie and Dong, Yuxiao},
  journal={arXiv preprint arXiv:2509.10446},
  year={2025}
}

@misc{claude4,
  title = {Introducing claude 4},
  author = {Anthropic},
  url = {https://www.anthropic.com/news/claude-4},
  year={2025}
}

@inproceedings{wu-etal-2025-webwalker,
    title = "{W}eb{W}alker: Benchmarking {LLM}s in Web Traversal",
    author = "Wu, Jialong  and
      Yin, Wenbiao  and
      Jiang, Yong  and
      Wang, Zhenglin  and
      Xi, Zekun  and
      Fang, Runnan  and
      Zhang, Linhai  and
      He, Yulan  and
      Zhou, Deyu  and
      Xie, Pengjun  and
      Huang, Fei",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.508/",
    doi = "10.18653/v1/2025.acl-long.508",
    pages = "10290--10305",
    ISBN = "979-8-89176-251-0",
    abstract = "Retrieval-augmented generation (RAG) demonstrates remarkable performance across tasks in open-domain question-answering. However, traditional search engines may retrieve shallow content, limiting the ability of LLMs to handle complex, multi-layered information. To address this, we introduce WebWalkerQA, a benchmark designed to assess the ability of LLMs to perform web traversal. It evaluates the capacity of LLMs to traverse a website{'}s subpages to extract high-quality data systematically. We propose WebWalker, which is a multi-agent framework that mimics human-like web navigation through an explore-critic paradigm. Extensive experimental results show that WebWalkerQA is challenging and demonstrates the effectiveness of RAG combined with WebWalker, through this horizontal and vertical integration in real-world scenarios."
}

@article{fang2025towards,
  title={Towards General Agentic Intelligence via Environment Scaling},
  author={Fang, Runnan and Cai, Shihao and Li, Baixuan and Wu, Jialong and Li, Guangyu and Yin, Wenbiao and Wang, Xinyu and Wang, Xiaobin and Su, Liangcai and Zhang, Zhen and others},
  journal={arXiv preprint arXiv:2509.13311},
  year={2025}
}