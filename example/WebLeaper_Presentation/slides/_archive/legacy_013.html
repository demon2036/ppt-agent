            <section>
                <h2>强化学习：混合奖励系统</h2>
                <div class="insight-box">
                    <strong>核心观点：</strong>针对实体密集型任务的奖励稀疏和评估困难问题，设计混合奖励系统
                </div>

                <div class="two-columns">
                    <div>
                        <h3>RL 面临的困境</h3>
                        <div class="observation-box">
                            <p><strong>1. 奖励稀疏 (Reward Sparsity)</strong></p>
                            <ul>
                                <li>问题：几十个实体全对才给奖励</li>
                                <li>后果：模型永远学不会（正反馈太少）</li>
                            </ul>
                        </div>

                        <div class="observation-box">
                            <p><strong>2. 评估困难 (Evaluation Challenge)</strong></p>
                            <ul>
                                <li><strong>Exact Match:</strong> 太死板，无法处理同义词（"USA" vs "United States"）</li>
                                <li><strong>LLM-as-a-Judge:</strong> 又贵又不稳定，难以大规模应用</li>
                            </ul>
                        </div>
                    </div>

                    <div>
                        <h3>解决方案：混合奖励 (Hybrid Reward)</h3>

                        <div class="solution-box">
                            <p><strong>核心：软 F-Score (Soft F-Score)</strong></p>

                            <p><strong>1. 语义相似度函数</strong></p>
                            <div class="formula-box">
                                \[s(e_o, e_r) \in [0, 1]\]
                            </div>
                            <small>理解同义词和语义等价</small>

                            <p><strong>2. 软召回率</strong></p>
                            <div class="formula-box">
                                \[\mathcal{R}_c = \frac{1}{|R|} \sum_{e_r \in R} \max_{e_o \in O} s(e_o, e_r)\]
                            </div>

                            <p><strong>3. 软精确率</strong></p>
                            <div class="formula-box">
                                \[\mathcal{P} = \frac{1}{|O|} \sum_{e_o \in O} \max_{e_r \in R} s(e_o, e_r)\]
                            </div>

                            <p><strong>4. WebLeaper 奖励</strong></p>
                            <div class="formula-box">
                                \[\mathcal{R}_{\w} = (1 + \omega^2) \frac{\mathcal{P} \cdot \mathcal{R}_c}{\omega^2 \mathcal{P} + \mathcal{R}_c}\]
                            </div>
                        </div>
                    </div>
                </div>

                <div class="insight-box" style="margin-top: 20px;">
                    <strong>优势：</strong>细粒度反馈 + 智能评估 + 兼容性（保留传统数据集的评估方式）
                </div>
            </section>
